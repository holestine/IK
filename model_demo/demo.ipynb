{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from vit_pytorch import ViT\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "from timer import Timer\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLPNet(nn.Module):\n",
    "    def __init__(self, image_size, num_classes, channels):\n",
    "        super(MLPNet, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(image_size * channels, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, num_classes)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNNet(nn.Module):\n",
    "    def __init__(self, num_classes, channels, image_height, image_width):\n",
    "        super(CNNNet, self).__init__()\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "        self.norm1 = nn.BatchNorm2d(32)\n",
    "        self.norm2 = nn.BatchNorm2d(64)\n",
    "        self.norm3 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(channels, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, 1)\n",
    "\n",
    "        fc_size = self.forward(torch.rand((1, channels, image_height, image_width)), True)\n",
    "\n",
    "        self.fc1 = nn.Linear(fc_size, 64)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x, get_fc_size=False):\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.conv3(x)\n",
    "        x = self.norm3(x)\n",
    "        x = F.relu(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        if get_fc_size:\n",
    "            return x.nelement()\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTNet(nn.Module): \n",
    "    def __init__(self, image_size, patch_size, num_classes, channels):\n",
    "        HIDDEN_SIZE = 768\n",
    "        DEPTH = 6\n",
    "        HEADS = 12\n",
    "        MLP_DIM = 3072\n",
    "        \n",
    "        super(ViTNet, self).__init__()\n",
    "        \n",
    "        self.model = ViT(\n",
    "                        image_size = image_size,\n",
    "                        patch_size = patch_size,\n",
    "                        num_classes = num_classes,\n",
    "                        dim = HIDDEN_SIZE,\n",
    "                        depth = DEPTH,\n",
    "                        heads = HEADS,\n",
    "                        mlp_dim = MLP_DIM,\n",
    "                        channels = channels,\n",
    "                        dropout = 0.1,\n",
    "                        emb_dropout = 0.1\n",
    "                        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridNet(nn.Module):\n",
    "    def __init__(self, image_size, channels, num_classes):\n",
    "        HIDDEN_SIZE = 768\n",
    "        DEPTH = 6\n",
    "        HEADS = 12\n",
    "        MLP_DIM = 3072\n",
    "\n",
    "        super(HybridNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(channels, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "\n",
    "        self.norm1 = nn.BatchNorm2d(32)\n",
    "        self.norm2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",

    "        image_width = int((math.sqrt(image_size) - 4) / 2)\n",
    "\n",
    "        self.vit = ViT(\n",
    "                        image_size = image_width ** 2,\n",
    "                        patch_size = int(image_width / 2),\n",
    "                        num_classes = num_classes,\n",
    "                        dim = HIDDEN_SIZE,\n",
    "                        depth = DEPTH,\n",
    "                        heads = HEADS,\n",
    "                        mlp_dim = MLP_DIM,\n",
    "                        channels = 64,\n",
    "                        dropout = 0.1,\n",
    "                        emb_dropout = 0.1\n",
    "                        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.vit(x)\n",
    "\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, dataset, modeltype, writer, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            with Timer(\"{} {}\".format(modeltype, dataset)):\n",
    "                output = model(data)\n",
    "\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy))\n",
    "    writer.add_scalar('Accuracy/{} {}'.format(modeltype, dataset), accuracy, epoch)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(batch_size, test_batch_size, lr, gamma, epochs, log_dir, log_interval):\n",
    "    # Determine if we should use a GPU\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "\n",
    "    # Reduce precision to speed up training\n",
    "    torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "    if use_cuda:\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    train_kwargs = {'batch_size': batch_size}\n",
    "    test_kwargs  = {'batch_size': test_batch_size}\n",
    "    if use_cuda:\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "    accuracies = {}\n",
    "    parameters = {}\n",
    "    \n",
    "    for dataset in DATASETS:\n",
    "        if dataset == \"MNIST\":\n",
    "            transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307), (0.3081))\n",
    "            ])\n",
    "            train_set = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "            test_set = datasets.MNIST('./data', train=False, transform=transform)\n",
    "            image_height = 28\n",
    "            image_width = 28\n",
    "            patch_size = 14\n",
    "            num_classes = 10\n",
    "            channels = 1\n",
    "        elif dataset == \"CIFAR10\":\n",
    "            transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "            ])\n",
    "            train_set = datasets.CIFAR10('./data', train=True, download=True, transform=transform)\n",
    "            test_set = datasets.CIFAR10('./data', train=False, transform=transform)\n",
    "            image_height = 32\n",
    "            image_width = 32\n",
    "            patch_size = 16\n",
    "            num_classes = 10\n",
    "            channels = 3\n",
    "        elif dataset == \"CIFAR100\":\n",
    "            transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "            ])\n",
    "            train_set = datasets.CIFAR100('./data', train=True, download=True, transform=transform)\n",
    "            test_set = datasets.CIFAR100('./data', train=False, transform=transform)\n",
    "            image_height = 32\n",
    "            image_width = 32\n",
    "            patch_size = 16\n",
    "            num_classes = 100\n",
    "            channels = 3\n",
    "\n",
    "        for model_type in MODEL_TYPES:\n",
    "            print(\"Evaluating {} with {}\".format(model_type, dataset))\n",
    "\n",
    "            train_loader = torch.utils.data.DataLoader(train_set,**train_kwargs)\n",
    "            test_loader  = torch.utils.data.DataLoader(test_set, **test_kwargs)\n",
    "\n",
    "            if model_type == \"MLP\":\n",
    "                model = MLPNet(image_height * image_width, num_classes, channels).to(device)\n",
    "            elif model_type == \"CNN\":\n",
    "                model = CNNNet(num_classes, channels, image_height, image_width).to(device)\n",
    "            elif model_type == \"ViT\":\n",
    "                model = ViTNet(image_height * image_width, patch_size, num_classes, channels).to(device)\n",
    "            elif model_type == \"HYBRID\":\n",
    "                model = HybridNet(image_height * image_width, channels, num_classes).to(device)\n",
    "            \n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "            scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "\n",
    "            max_accuracy = 0\n",
    "            writer = SummaryWriter(log_dir=log_dir)\n",
    "            for epoch in range(1, epochs + 1):\n",
    "                train(model, device, train_loader, optimizer, epoch, log_interval)\n",
    "                accuracy = test(model, device, test_loader, dataset, model_type, writer, epoch)\n",
    "                max_accuracy = max(accuracy, max_accuracy)\n",
    "                scheduler.step()\n",
    "                if (max_accuracy > 98):\n",
    "                    print('Breaking at epoch {}'.format(epoch))\n",
    "                    break\n",
    "\n",
    "            accuracies[\"{} {}\".format(model_type, dataset)] = max_accuracy\n",
    "            parameters[\"{} {}\".format(model_type, dataset)] = count_parameters(model)\n",
    "\n",
    "            torch.save(model.state_dict(), \"{}_{}.pt\".format(model_type, dataset))\n",
    "\n",
    "    return accuracies, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MLP with MNIST\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.313186\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.291735\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.271536\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.227570\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.146103\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.110559\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.050249\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 1.928809\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.781616\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 1.616427\n",
      "\n",
      "Test set: Average loss: 1.4351, Accuracy: 7033/10000 (70%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.590005\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 1.426962\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 1.375163\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 1.118657\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.216858\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.187923\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.122759\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 1.298799\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.163026\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.921626\n",
      "\n",
      "Test set: Average loss: 0.8485, Accuracy: 7976/10000 (80%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.976820\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.946038\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.980630\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 1.009976\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.034002\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.060187\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.952013\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.831572\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.995418\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.775347\n",
      "\n",
      "Test set: Average loss: 0.6863, Accuracy: 8266/10000 (83%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.843223\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.989597\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.885013\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.743548\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.898660\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.949596\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.882910\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.743546\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.822534\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.806583\n",
      "\n",
      "Test set: Average loss: 0.6146, Accuracy: 8397/10000 (84%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.809766\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.830594\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.860402\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.756702\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.801913\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.682899\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.651012\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.734781\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.682950\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.742700\n",
      "\n",
      "Test set: Average loss: 0.5756, Accuracy: 8472/10000 (85%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.737399\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.953105\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.803773\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.664251\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.881598\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 1.077498\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.893422\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.728083\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.605461\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.702426\n",
      "\n",
      "Test set: Average loss: 0.5520, Accuracy: 8523/10000 (85%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.735996\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.689932\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.770270\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.642564\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.712527\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.692038\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.835182\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.741603\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.727858\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.902065\n",
      "\n",
      "Test set: Average loss: 0.5371, Accuracy: 8563/10000 (86%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.619289\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.656359\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.575114\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.628948\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.557854\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.614083\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.587081\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.776232\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.878441\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.529885\n",
      "\n",
      "Test set: Average loss: 0.5274, Accuracy: 8582/10000 (86%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.769872\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.640432\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.763371\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.706036\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.623825\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.555225\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.746588\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.607596\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.530387\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.881419\n",
      "\n",
      "Test set: Average loss: 0.5207, Accuracy: 8605/10000 (86%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.625533\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.848006\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.860545\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.875568\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.654416\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.805670\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.656235\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.728476\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.614918\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.787308\n",
      "\n",
      "Test set: Average loss: 0.5163, Accuracy: 8617/10000 (86%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.756614\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.556423\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.892619\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.561444\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.700967\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.736405\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.790203\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.675712\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.635573\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.673397\n",
      "\n",
      "Test set: Average loss: 0.5134, Accuracy: 8621/10000 (86%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.682910\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.624247\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.631033\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.553757\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.608406\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.623488\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.595945\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.803816\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.651242\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.702264\n",
      "\n",
      "Test set: Average loss: 0.5112, Accuracy: 8628/10000 (86%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.630220\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.743274\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.674892\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.619414\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.670770\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.739440\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.784535\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.610054\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.626350\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.530896\n",
      "\n",
      "Test set: Average loss: 0.5098, Accuracy: 8633/10000 (86%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.730687\n",
      "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.721410\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.701956\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.660592\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.755612\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.666739\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.567075\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.674944\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.787396\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.763541\n",
      "\n",
      "Test set: Average loss: 0.5088, Accuracy: 8634/10000 (86%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.563263\n",
      "Train Epoch: 15 [6400/60000 (11%)]\tLoss: 0.799274\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.912602\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 0.801284\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.684870\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.729095\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.552432\n",
      "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 0.771151\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.581470\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 0.683271\n",
      "\n",
      "Test set: Average loss: 0.5081, Accuracy: 8635/10000 (86%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.788725\n",
      "Train Epoch: 16 [6400/60000 (11%)]\tLoss: 0.641803\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.656921\n",
      "Train Epoch: 16 [19200/60000 (32%)]\tLoss: 0.586680\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.512929\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 0.585041\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.642519\n",
      "Train Epoch: 16 [44800/60000 (75%)]\tLoss: 0.650172\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.809365\n",
      "Train Epoch: 16 [57600/60000 (96%)]\tLoss: 0.581991\n",
      "\n",
      "Test set: Average loss: 0.5076, Accuracy: 8637/10000 (86%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.854340\n",
      "Train Epoch: 17 [6400/60000 (11%)]\tLoss: 0.761848\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.587041\n",
      "Train Epoch: 17 [19200/60000 (32%)]\tLoss: 0.829191\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.525393\n",
      "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 0.501919\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.607702\n",
      "Train Epoch: 17 [44800/60000 (75%)]\tLoss: 0.713808\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.631390\n",
      "Train Epoch: 17 [57600/60000 (96%)]\tLoss: 0.656396\n",
      "\n",
      "Test set: Average loss: 0.5072, Accuracy: 8637/10000 (86%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.601793\n",
      "Train Epoch: 18 [6400/60000 (11%)]\tLoss: 0.660212\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.629538\n",
      "Train Epoch: 18 [19200/60000 (32%)]\tLoss: 0.776097\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.743125\n",
      "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 0.582293\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.820049\n",
      "Train Epoch: 18 [44800/60000 (75%)]\tLoss: 0.804848\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.529414\n",
      "Train Epoch: 18 [57600/60000 (96%)]\tLoss: 0.753784\n",
      "\n",
      "Test set: Average loss: 0.5070, Accuracy: 8639/10000 (86%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.646440\n",
      "Train Epoch: 19 [6400/60000 (11%)]\tLoss: 0.739099\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.630803\n",
      "Train Epoch: 19 [19200/60000 (32%)]\tLoss: 0.625810\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.655065\n",
      "Train Epoch: 19 [32000/60000 (53%)]\tLoss: 0.702576\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.624864\n",
      "Train Epoch: 19 [44800/60000 (75%)]\tLoss: 0.669887\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.698085\n",
      "Train Epoch: 19 [57600/60000 (96%)]\tLoss: 0.765528\n",
      "\n",
      "Test set: Average loss: 0.5068, Accuracy: 8640/10000 (86%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.557188\n",
      "Train Epoch: 20 [6400/60000 (11%)]\tLoss: 0.691612\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.715788\n",
      "Train Epoch: 20 [19200/60000 (32%)]\tLoss: 0.679768\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.699332\n",
      "Train Epoch: 20 [32000/60000 (53%)]\tLoss: 0.543366\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.752897\n",
      "Train Epoch: 20 [44800/60000 (75%)]\tLoss: 0.631462\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.686579\n",
      "Train Epoch: 20 [57600/60000 (96%)]\tLoss: 0.772592\n",
      "\n",
      "Test set: Average loss: 0.5067, Accuracy: 8642/10000 (86%)\n",
      "\n",
      "Evaluating CNN with MNIST\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.318340\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.173822\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.022372\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.833100\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.693211\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.474622\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.468104\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 1.320660\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.152813\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 1.028154\n",
      "\n",
      "Test set: Average loss: 1.2145, Accuracy: 8186/10000 (82%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.112676\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.986439\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.897462\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.898780\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.710990\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.810123\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.686775\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.659714\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.608041\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.539958\n",
      "\n",
      "Test set: Average loss: 0.8115, Accuracy: 8742/10000 (87%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.623272\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.501040\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.655296\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.509496\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.414818\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.415098\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.477968\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.450340\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.401042\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.437027\n",
      "\n",
      "Test set: Average loss: 0.6426, Accuracy: 8974/10000 (90%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.401407\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.424855\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.393262\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.463057\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.443784\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.353821\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.384502\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.332695\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.355222\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.412512\n",
      "\n",
      "Test set: Average loss: 0.5465, Accuracy: 9083/10000 (91%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.440514\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.388797\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.346185\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.256060\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.362468\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.248658\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.363057\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.391481\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.348766\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.297157\n",
      "\n",
      "Test set: Average loss: 0.4879, Accuracy: 9174/10000 (92%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.219619\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.300740\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.264360\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.183821\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.261099\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.236880\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.297348\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.271076\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.305946\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.207361\n",
      "\n",
      "Test set: Average loss: 0.4684, Accuracy: 9166/10000 (92%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.322818\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.264099\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.212172\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.305176\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.329815\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.205828\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.277827\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.377764\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.181946\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.289202\n",
      "\n",
      "Test set: Average loss: 0.4417, Accuracy: 9202/10000 (92%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.293976\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.285322\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.268396\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.281954\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.263369\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.253642\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.134002\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.249433\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.239173\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.225955\n",
      "\n",
      "Test set: Average loss: 0.4250, Accuracy: 9239/10000 (92%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.337813\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.315123\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.143886\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.267546\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.159359\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.225269\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.320823\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.167724\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.220925\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.398769\n",
      "\n",
      "Test set: Average loss: 0.4101, Accuracy: 9261/10000 (93%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.257613\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.223074\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.266226\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.292570\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.265337\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.208192\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.283124\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.188922\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.180146\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.199870\n",
      "\n",
      "Test set: Average loss: 0.4033, Accuracy: 9267/10000 (93%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.245212\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.271898\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.236879\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.200797\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.214698\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.271259\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.216960\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.266197\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.262753\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.184491\n",
      "\n",
      "Test set: Average loss: 0.4199, Accuracy: 9225/10000 (92%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.203967\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.229204\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.320466\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.184239\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.145367\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.248381\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.275532\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.159188\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.210728\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.309176\n",
      "\n",
      "Test set: Average loss: 0.4148, Accuracy: 9223/10000 (92%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.340857\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.242494\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.253785\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.188951\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.191820\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.217843\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.247116\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.219291\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.355075\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.195913\n",
      "\n",
      "Test set: Average loss: 0.3936, Accuracy: 9272/10000 (93%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.270774\n",
      "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.249882\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.176373\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.238977\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.273491\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.192662\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.285845\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.233765\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.278788\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.286183\n",
      "\n",
      "Test set: Average loss: 0.4042, Accuracy: 9240/10000 (92%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.185212\n",
      "Train Epoch: 15 [6400/60000 (11%)]\tLoss: 0.266992\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.309739\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 0.266765\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.267586\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.282878\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.266309\n",
      "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 0.377242\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.136956\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 0.251188\n",
      "\n",
      "Test set: Average loss: 0.3926, Accuracy: 9272/10000 (93%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.187229\n",
      "Train Epoch: 16 [6400/60000 (11%)]\tLoss: 0.276042\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.216275\n",
      "Train Epoch: 16 [19200/60000 (32%)]\tLoss: 0.285507\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.234830\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 0.151643\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.278540\n",
      "Train Epoch: 16 [44800/60000 (75%)]\tLoss: 0.292283\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.283770\n",
      "Train Epoch: 16 [57600/60000 (96%)]\tLoss: 0.206540\n",
      "\n",
      "Test set: Average loss: 0.4074, Accuracy: 9232/10000 (92%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.288164\n",
      "Train Epoch: 17 [6400/60000 (11%)]\tLoss: 0.243851\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.156652\n",
      "Train Epoch: 17 [19200/60000 (32%)]\tLoss: 0.162883\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.176163\n",
      "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 0.284661\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.163410\n",
      "Train Epoch: 17 [44800/60000 (75%)]\tLoss: 0.212771\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.211572\n",
      "Train Epoch: 17 [57600/60000 (96%)]\tLoss: 0.207653\n",
      "\n",
      "Test set: Average loss: 0.3991, Accuracy: 9258/10000 (93%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.261350\n",
      "Train Epoch: 18 [6400/60000 (11%)]\tLoss: 0.300498\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.158950\n",
      "Train Epoch: 18 [19200/60000 (32%)]\tLoss: 0.243190\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.383555\n",
      "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 0.205904\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.259950\n",
      "Train Epoch: 18 [44800/60000 (75%)]\tLoss: 0.212312\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.195833\n",
      "Train Epoch: 18 [57600/60000 (96%)]\tLoss: 0.293961\n",
      "\n",
      "Test set: Average loss: 0.4118, Accuracy: 9230/10000 (92%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.176247\n",
      "Train Epoch: 19 [6400/60000 (11%)]\tLoss: 0.150925\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.235529\n",
      "Train Epoch: 19 [19200/60000 (32%)]\tLoss: 0.196497\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.264285\n",
      "Train Epoch: 19 [32000/60000 (53%)]\tLoss: 0.201239\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.339058\n",
      "Train Epoch: 19 [44800/60000 (75%)]\tLoss: 0.231706\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.189286\n",
      "Train Epoch: 19 [57600/60000 (96%)]\tLoss: 0.198981\n",
      "\n",
      "Test set: Average loss: 0.4025, Accuracy: 9239/10000 (92%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.265833\n",
      "Train Epoch: 20 [6400/60000 (11%)]\tLoss: 0.247745\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.174419\n",
      "Train Epoch: 20 [19200/60000 (32%)]\tLoss: 0.280859\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.180568\n",
      "Train Epoch: 20 [32000/60000 (53%)]\tLoss: 0.252145\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.163078\n",
      "Train Epoch: 20 [44800/60000 (75%)]\tLoss: 0.190321\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.179859\n",
      "Train Epoch: 20 [57600/60000 (96%)]\tLoss: 0.138682\n",
      "\n",
      "Test set: Average loss: 0.3989, Accuracy: 9258/10000 (93%)\n",
      "\n",
      "Evaluating ViT with MNIST\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.608520\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.775179\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.557065\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.426585\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.522883\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.330190\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.169271\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.430748\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.152775\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.209397\n",
      "\n",
      "Test set: Average loss: 0.1740, Accuracy: 9490/10000 (95%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.176157\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.269608\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.279195\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.138092\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.062812\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.090376\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.271487\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.114888\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.157633\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.410145\n",
      "\n",
      "Test set: Average loss: 0.1216, Accuracy: 9639/10000 (96%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.183305\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.119682\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.096250\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.200601\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.103282\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.065496\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.232678\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.160646\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.087256\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.062849\n",
      "\n",
      "Test set: Average loss: 0.0983, Accuracy: 9696/10000 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.079493\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.124732\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.090652\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.176795\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.170860\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.116549\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.103530\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.078419\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.228396\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.160998\n",
      "\n",
      "Test set: Average loss: 0.0889, Accuracy: 9721/10000 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.059554\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.128404\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.057412\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.173713\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.079429\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.108217\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.178355\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.087502\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.176087\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.126606\n",
      "\n",
      "Test set: Average loss: 0.0835, Accuracy: 9739/10000 (97%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.039291\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.037974\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.075874\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.083470\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.141638\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.183873\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.098422\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.171391\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.072997\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.171598\n",
      "\n",
      "Test set: Average loss: 0.0811, Accuracy: 9752/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.035343\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.095642\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.065515\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.078456\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.075551\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.036204\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.064846\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.077206\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.182359\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.100741\n",
      "\n",
      "Test set: Average loss: 0.0766, Accuracy: 9758/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.156827\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.102778\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.123658\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.039426\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.093417\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.144524\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.103937\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.147875\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.079242\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.110920\n",
      "\n",
      "Test set: Average loss: 0.0776, Accuracy: 9749/10000 (97%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.124924\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.022379\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.057926\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.049488\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.188148\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.020424\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.082011\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.084337\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.057910\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.101204\n",
      "\n",
      "Test set: Average loss: 0.0745, Accuracy: 9770/10000 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.092240\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.079384\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.152730\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.050214\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.061170\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.089755\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.062853\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.020594\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.058994\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.037663\n",
      "\n",
      "Test set: Average loss: 0.0743, Accuracy: 9769/10000 (98%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.140880\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.037324\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.133605\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.065290\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.109104\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.118117\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.045732\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.047502\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.015378\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.072126\n",
      "\n",
      "Test set: Average loss: 0.0741, Accuracy: 9765/10000 (98%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.020103\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.098483\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.081420\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.055134\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.016654\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.091142\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.042863\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.141153\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.031717\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.112279\n",
      "\n",
      "Test set: Average loss: 0.0734, Accuracy: 9771/10000 (98%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.084416\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.080520\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.167606\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.086800\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.186570\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.021689\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.197153\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.167837\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.055410\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.050437\n",
      "\n",
      "Test set: Average loss: 0.0732, Accuracy: 9771/10000 (98%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.145767\n",
      "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.057246\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.037742\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.160051\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.050700\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.059015\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.054372\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.047571\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.075867\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.102202\n",
      "\n",
      "Test set: Average loss: 0.0730, Accuracy: 9769/10000 (98%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.067502\n",
      "Train Epoch: 15 [6400/60000 (11%)]\tLoss: 0.068398\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.135468\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 0.098662\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.050725\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.069055\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.141831\n",
      "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 0.071971\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.054382\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 0.233124\n",
      "\n",
      "Test set: Average loss: 0.0729, Accuracy: 9772/10000 (98%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.092462\n",
      "Train Epoch: 16 [6400/60000 (11%)]\tLoss: 0.137080\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.069920\n",
      "Train Epoch: 16 [19200/60000 (32%)]\tLoss: 0.048097\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.039747\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 0.091732\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.069661\n",
      "Train Epoch: 16 [44800/60000 (75%)]\tLoss: 0.146301\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.112845\n",
      "Train Epoch: 16 [57600/60000 (96%)]\tLoss: 0.159042\n",
      "\n",
      "Test set: Average loss: 0.0729, Accuracy: 9771/10000 (98%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.104273\n",
      "Train Epoch: 17 [6400/60000 (11%)]\tLoss: 0.012631\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.018987\n",
      "Train Epoch: 17 [19200/60000 (32%)]\tLoss: 0.087604\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.125381\n",
      "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 0.061357\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.040714\n",
      "Train Epoch: 17 [44800/60000 (75%)]\tLoss: 0.057123\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.018040\n",
      "Train Epoch: 17 [57600/60000 (96%)]\tLoss: 0.095882\n",
      "\n",
      "Test set: Average loss: 0.0729, Accuracy: 9771/10000 (98%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.062231\n",
      "Train Epoch: 18 [6400/60000 (11%)]\tLoss: 0.024138\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.105607\n",
      "Train Epoch: 18 [19200/60000 (32%)]\tLoss: 0.087360\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.113737\n",
      "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 0.019994\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.026559\n",
      "Train Epoch: 18 [44800/60000 (75%)]\tLoss: 0.087865\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.260000\n",
      "Train Epoch: 18 [57600/60000 (96%)]\tLoss: 0.069075\n",
      "\n",
      "Test set: Average loss: 0.0729, Accuracy: 9772/10000 (98%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.116893\n",
      "Train Epoch: 19 [6400/60000 (11%)]\tLoss: 0.077159\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.073633\n",
      "Train Epoch: 19 [19200/60000 (32%)]\tLoss: 0.067069\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.152387\n",
      "Train Epoch: 19 [32000/60000 (53%)]\tLoss: 0.029406\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.137696\n",
      "Train Epoch: 19 [44800/60000 (75%)]\tLoss: 0.052954\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.086168\n",
      "Train Epoch: 19 [57600/60000 (96%)]\tLoss: 0.164745\n",
      "\n",
      "Test set: Average loss: 0.0729, Accuracy: 9771/10000 (98%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.028470\n",
      "Train Epoch: 20 [6400/60000 (11%)]\tLoss: 0.007400\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.044160\n",
      "Train Epoch: 20 [19200/60000 (32%)]\tLoss: 0.063017\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.139772\n",
      "Train Epoch: 20 [32000/60000 (53%)]\tLoss: 0.038349\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.077273\n",
      "Train Epoch: 20 [44800/60000 (75%)]\tLoss: 0.102313\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.085727\n",
      "Train Epoch: 20 [57600/60000 (96%)]\tLoss: 0.051596\n",
      "\n",
      "Test set: Average loss: 0.0729, Accuracy: 9771/10000 (98%)\n",
      "\n",
      "Evaluating HYBRID with MNIST\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.628788\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.703523\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.277197\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.452509\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.109856\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.105576\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.252386\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.113739\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.171085\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.104519\n",
      "\n",
      "Test set: Average loss: 0.0961, Accuracy: 9699/10000 (97%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.092984\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.145185\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.099404\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.094669\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.049163\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.180013\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.064649\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.093860\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.117922\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.039678\n",
      "\n",
      "Test set: Average loss: 0.0596, Accuracy: 9819/10000 (98%)\n",
      "\n",
      "Breaking at epoch 2\n",
      "Files already downloaded and verified\n",
      "Evaluating MLP with CIFAR10\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.303364\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 2.291962\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 2.282117\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 2.250348\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 2.190280\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 2.190451\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 2.207686\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 2.096140\n",
      "\n",
      "Test set: Average loss: 2.0886, Accuracy: 2701/10000 (27%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 2.160544\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 2.156094\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 2.178412\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 2.006575\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.913016\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 2.044146\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.968341\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 1.964782\n",
      "\n",
      "Test set: Average loss: 1.9847, Accuracy: 2915/10000 (29%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.997588\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 1.986352\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 2.029459\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 1.950872\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.985423\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.873509\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.957635\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 1.995136\n",
      "\n",
      "Test set: Average loss: 1.9340, Accuracy: 3122/10000 (31%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.962239\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 1.978138\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 2.012840\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 1.987579\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.876542\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 1.945192\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.855847\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 1.810159\n",
      "\n",
      "Test set: Average loss: 1.9048, Accuracy: 3232/10000 (32%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.795348\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 1.924617\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 2.040199\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 1.926392\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 2.158985\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 1.963637\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 1.981760\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 1.956558\n",
      "\n",
      "Test set: Average loss: 1.8872, Accuracy: 3317/10000 (33%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.965536\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 1.974306\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 2.088330\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 1.921782\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 1.783653\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 2.001987\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 1.867143\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 1.859025\n",
      "\n",
      "Test set: Average loss: 1.8756, Accuracy: 3361/10000 (34%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 2.013258\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 1.885215\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 1.879949\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 1.953488\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 1.920402\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 1.894182\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 2.065243\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 1.838874\n",
      "\n",
      "Test set: Average loss: 1.8678, Accuracy: 3396/10000 (34%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 1.745351\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 1.898519\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 1.750614\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 2.078647\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 1.878421\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 1.976311\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 2.048394\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 1.804812\n",
      "\n",
      "Test set: Average loss: 1.8628, Accuracy: 3423/10000 (34%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 1.861446\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 2.181321\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 1.893239\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 1.836253\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 1.925557\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 1.962306\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 2.083256\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 1.976377\n",
      "\n",
      "Test set: Average loss: 1.8594, Accuracy: 3441/10000 (34%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 1.855765\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 2.059853\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 1.655353\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 1.760442\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 1.948287\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 1.967407\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 1.783771\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 1.804484\n",
      "\n",
      "Test set: Average loss: 1.8570, Accuracy: 3455/10000 (35%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 1.918186\n",
      "Train Epoch: 11 [6400/50000 (13%)]\tLoss: 1.865803\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 1.883254\n",
      "Train Epoch: 11 [19200/50000 (38%)]\tLoss: 1.848523\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 2.088330\n",
      "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 1.939397\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 1.777632\n",
      "Train Epoch: 11 [44800/50000 (90%)]\tLoss: 1.890259\n",
      "\n",
      "Test set: Average loss: 1.8553, Accuracy: 3461/10000 (35%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 1.802315\n",
      "Train Epoch: 12 [6400/50000 (13%)]\tLoss: 1.887823\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 1.839522\n",
      "Train Epoch: 12 [19200/50000 (38%)]\tLoss: 2.033296\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 2.001463\n",
      "Train Epoch: 12 [32000/50000 (64%)]\tLoss: 1.910787\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 1.828816\n",
      "Train Epoch: 12 [44800/50000 (90%)]\tLoss: 1.798510\n",
      "\n",
      "Test set: Average loss: 1.8542, Accuracy: 3460/10000 (35%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 1.823417\n",
      "Train Epoch: 13 [6400/50000 (13%)]\tLoss: 1.855059\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 1.945792\n",
      "Train Epoch: 13 [19200/50000 (38%)]\tLoss: 1.910718\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 1.865944\n",
      "Train Epoch: 13 [32000/50000 (64%)]\tLoss: 1.896718\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 1.949617\n",
      "Train Epoch: 13 [44800/50000 (90%)]\tLoss: 1.800341\n",
      "\n",
      "Test set: Average loss: 1.8534, Accuracy: 3464/10000 (35%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 1.872617\n",
      "Train Epoch: 14 [6400/50000 (13%)]\tLoss: 1.843667\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 1.835923\n",
      "Train Epoch: 14 [19200/50000 (38%)]\tLoss: 1.841759\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 2.037123\n",
      "Train Epoch: 14 [32000/50000 (64%)]\tLoss: 1.969531\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 1.895929\n",
      "Train Epoch: 14 [44800/50000 (90%)]\tLoss: 1.722757\n",
      "\n",
      "Test set: Average loss: 1.8528, Accuracy: 3468/10000 (35%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 1.938039\n",
      "Train Epoch: 15 [6400/50000 (13%)]\tLoss: 1.932728\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 1.888766\n",
      "Train Epoch: 15 [19200/50000 (38%)]\tLoss: 1.888611\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 1.698260\n",
      "Train Epoch: 15 [32000/50000 (64%)]\tLoss: 1.899296\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 1.871922\n",
      "Train Epoch: 15 [44800/50000 (90%)]\tLoss: 1.873733\n",
      "\n",
      "Test set: Average loss: 1.8524, Accuracy: 3473/10000 (35%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 1.896264\n",
      "Train Epoch: 16 [6400/50000 (13%)]\tLoss: 1.854140\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 1.861764\n",
      "Train Epoch: 16 [19200/50000 (38%)]\tLoss: 2.081824\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 1.839132\n",
      "Train Epoch: 16 [32000/50000 (64%)]\tLoss: 1.895831\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 1.819053\n",
      "Train Epoch: 16 [44800/50000 (90%)]\tLoss: 2.004926\n",
      "\n",
      "Test set: Average loss: 1.8522, Accuracy: 3473/10000 (35%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 2.045783\n",
      "Train Epoch: 17 [6400/50000 (13%)]\tLoss: 1.861183\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 1.766928\n",
      "Train Epoch: 17 [19200/50000 (38%)]\tLoss: 1.910606\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 1.896202\n",
      "Train Epoch: 17 [32000/50000 (64%)]\tLoss: 1.923352\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 1.672962\n",
      "Train Epoch: 17 [44800/50000 (90%)]\tLoss: 1.934270\n",
      "\n",
      "Test set: Average loss: 1.8520, Accuracy: 3475/10000 (35%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 1.945211\n",
      "Train Epoch: 18 [6400/50000 (13%)]\tLoss: 1.974799\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 1.918624\n",
      "Train Epoch: 18 [19200/50000 (38%)]\tLoss: 1.897329\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 1.764748\n",
      "Train Epoch: 18 [32000/50000 (64%)]\tLoss: 1.888490\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 1.811676\n",
      "Train Epoch: 18 [44800/50000 (90%)]\tLoss: 1.907213\n",
      "\n",
      "Test set: Average loss: 1.8518, Accuracy: 3475/10000 (35%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 1.926562\n",
      "Train Epoch: 19 [6400/50000 (13%)]\tLoss: 1.940911\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 1.788275\n",
      "Train Epoch: 19 [19200/50000 (38%)]\tLoss: 2.047669\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 1.889383\n",
      "Train Epoch: 19 [32000/50000 (64%)]\tLoss: 2.163939\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 2.089432\n",
      "Train Epoch: 19 [44800/50000 (90%)]\tLoss: 1.943875\n",
      "\n",
      "Test set: Average loss: 1.8517, Accuracy: 3475/10000 (35%)\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 1.992561\n",
      "Train Epoch: 20 [6400/50000 (13%)]\tLoss: 1.949269\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 1.812757\n",
      "Train Epoch: 20 [19200/50000 (38%)]\tLoss: 2.068188\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 1.984226\n",
      "Train Epoch: 20 [32000/50000 (64%)]\tLoss: 1.732181\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 1.897586\n",
      "Train Epoch: 20 [44800/50000 (90%)]\tLoss: 1.935812\n",
      "\n",
      "Test set: Average loss: 1.8517, Accuracy: 3475/10000 (35%)\n",
      "\n",
      "Evaluating CNN with CIFAR10\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.313833\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 2.283886\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 2.194152\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 2.157163\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 2.110180\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.959539\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.832464\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 1.908044\n",
      "\n",
      "Test set: Average loss: 1.9334, Accuracy: 3421/10000 (34%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.917633\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 1.859561\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.822875\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 1.791197\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.750674\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.711638\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.678621\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 1.638751\n",
      "\n",
      "Test set: Average loss: 1.8232, Accuracy: 3450/10000 (34%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.666160\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 1.692016\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.579369\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 1.594510\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.588831\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.579715\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.597521\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 1.610202\n",
      "\n",
      "Test set: Average loss: 1.7528, Accuracy: 3704/10000 (37%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.557660\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 1.709460\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.570538\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 1.593468\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.714646\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 1.660008\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.614309\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 1.666704\n",
      "\n",
      "Test set: Average loss: 1.6951, Accuracy: 3921/10000 (39%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.582954\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 1.641882\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 1.627388\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 1.471930\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.535227\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 1.727936\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 1.627828\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 1.562132\n",
      "\n",
      "Test set: Average loss: 1.6993, Accuracy: 3903/10000 (39%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.572514\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 1.772679\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 1.559157\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 1.643390\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 1.721631\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 1.595727\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 1.419840\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 1.556313\n",
      "\n",
      "Test set: Average loss: 1.6701, Accuracy: 3998/10000 (40%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 1.520901\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 1.490296\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 1.635772\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 1.624429\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 1.512435\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 1.403728\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 1.414818\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 1.530555\n",
      "\n",
      "Test set: Average loss: 1.6668, Accuracy: 4012/10000 (40%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 1.585136\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 1.381929\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 1.641701\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 1.554386\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 1.387263\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 1.475452\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 1.629340\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 1.561442\n",
      "\n",
      "Test set: Average loss: 1.6453, Accuracy: 4094/10000 (41%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 1.543741\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 1.737456\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 1.432660\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 1.384924\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 1.635033\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 1.450464\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 1.563648\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 1.531519\n",
      "\n",
      "Test set: Average loss: 1.6293, Accuracy: 4200/10000 (42%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 1.509008\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 1.616482\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 1.480691\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 1.622983\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 1.500783\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 1.449438\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 1.540384\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 1.614500\n",
      "\n",
      "Test set: Average loss: 1.6414, Accuracy: 4079/10000 (41%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 1.506534\n",
      "Train Epoch: 11 [6400/50000 (13%)]\tLoss: 1.607090\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 1.595111\n",
      "Train Epoch: 11 [19200/50000 (38%)]\tLoss: 1.508201\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 1.500187\n",
      "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 1.354015\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 1.385779\n",
      "Train Epoch: 11 [44800/50000 (90%)]\tLoss: 1.364838\n",
      "\n",
      "Test set: Average loss: 1.6289, Accuracy: 4194/10000 (42%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 1.508491\n",
      "Train Epoch: 12 [6400/50000 (13%)]\tLoss: 1.358396\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 1.566195\n",
      "Train Epoch: 12 [19200/50000 (38%)]\tLoss: 1.445899\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 1.574250\n",
      "Train Epoch: 12 [32000/50000 (64%)]\tLoss: 1.533706\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 1.234893\n",
      "Train Epoch: 12 [44800/50000 (90%)]\tLoss: 1.470900\n",
      "\n",
      "Test set: Average loss: 1.6246, Accuracy: 4193/10000 (42%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 1.519801\n",
      "Train Epoch: 13 [6400/50000 (13%)]\tLoss: 1.387668\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 1.464976\n",
      "Train Epoch: 13 [19200/50000 (38%)]\tLoss: 1.477098\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 1.634720\n",
      "Train Epoch: 13 [32000/50000 (64%)]\tLoss: 1.234262\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 1.611976\n",
      "Train Epoch: 13 [44800/50000 (90%)]\tLoss: 1.497276\n",
      "\n",
      "Test set: Average loss: 1.6510, Accuracy: 4128/10000 (41%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 1.566424\n",
      "Train Epoch: 14 [6400/50000 (13%)]\tLoss: 1.399976\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 1.462643\n",
      "Train Epoch: 14 [19200/50000 (38%)]\tLoss: 1.553149\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 1.357039\n",
      "Train Epoch: 14 [32000/50000 (64%)]\tLoss: 1.467683\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 1.680929\n",
      "Train Epoch: 14 [44800/50000 (90%)]\tLoss: 1.430882\n",
      "\n",
      "Test set: Average loss: 1.6425, Accuracy: 4118/10000 (41%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 1.755322\n",
      "Train Epoch: 15 [6400/50000 (13%)]\tLoss: 1.582380\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 1.474497\n",
      "Train Epoch: 15 [19200/50000 (38%)]\tLoss: 1.709132\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 1.629604\n",
      "Train Epoch: 15 [32000/50000 (64%)]\tLoss: 1.479353\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 1.399133\n",
      "Train Epoch: 15 [44800/50000 (90%)]\tLoss: 1.339904\n",
      "\n",
      "Test set: Average loss: 1.6310, Accuracy: 4171/10000 (42%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 1.390868\n",
      "Train Epoch: 16 [6400/50000 (13%)]\tLoss: 1.400782\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 1.609170\n",
      "Train Epoch: 16 [19200/50000 (38%)]\tLoss: 1.593917\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 1.505979\n",
      "Train Epoch: 16 [32000/50000 (64%)]\tLoss: 1.405187\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 1.547850\n",
      "Train Epoch: 16 [44800/50000 (90%)]\tLoss: 1.511215\n",
      "\n",
      "Test set: Average loss: 1.6325, Accuracy: 4181/10000 (42%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 1.375483\n",
      "Train Epoch: 17 [6400/50000 (13%)]\tLoss: 1.565142\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 1.639549\n",
      "Train Epoch: 17 [19200/50000 (38%)]\tLoss: 1.680108\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 1.657226\n",
      "Train Epoch: 17 [32000/50000 (64%)]\tLoss: 1.404069\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 1.508167\n",
      "Train Epoch: 17 [44800/50000 (90%)]\tLoss: 1.600451\n",
      "\n",
      "Test set: Average loss: 1.6304, Accuracy: 4233/10000 (42%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 1.591946\n",
      "Train Epoch: 18 [6400/50000 (13%)]\tLoss: 1.639297\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 1.681052\n",
      "Train Epoch: 18 [19200/50000 (38%)]\tLoss: 1.605431\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 1.590962\n",
      "Train Epoch: 18 [32000/50000 (64%)]\tLoss: 1.643273\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 1.513907\n",
      "Train Epoch: 18 [44800/50000 (90%)]\tLoss: 1.376613\n",
      "\n",
      "Test set: Average loss: 1.6299, Accuracy: 4197/10000 (42%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 1.358520\n",
      "Train Epoch: 19 [6400/50000 (13%)]\tLoss: 1.500567\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 1.741540\n",
      "Train Epoch: 19 [19200/50000 (38%)]\tLoss: 1.468216\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 1.433674\n",
      "Train Epoch: 19 [32000/50000 (64%)]\tLoss: 1.494489\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 1.428731\n",
      "Train Epoch: 19 [44800/50000 (90%)]\tLoss: 1.479579\n",
      "\n",
      "Test set: Average loss: 1.6377, Accuracy: 4139/10000 (41%)\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 1.436595\n",
      "Train Epoch: 20 [6400/50000 (13%)]\tLoss: 1.533851\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 1.540057\n",
      "Train Epoch: 20 [19200/50000 (38%)]\tLoss: 1.635062\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 1.509651\n",
      "Train Epoch: 20 [32000/50000 (64%)]\tLoss: 1.552413\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 1.431223\n",
      "Train Epoch: 20 [44800/50000 (90%)]\tLoss: 1.400274\n",
      "\n",
      "Test set: Average loss: 1.6273, Accuracy: 4167/10000 (42%)\n",
      "\n",
      "Evaluating ViT with CIFAR10\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.370575\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 2.001761\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 2.013412\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 1.944882\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.753516\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.658910\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.579185\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 1.786427\n",
      "\n",
      "Test set: Average loss: 1.6707, Accuracy: 4139/10000 (41%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.508213\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 1.748769\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.629989\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 1.610817\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.525275\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.566910\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.454852\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 1.608126\n",
      "\n",
      "Test set: Average loss: 1.5635, Accuracy: 4529/10000 (45%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.593617\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 1.724110\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.549486\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 1.555977\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.597412\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.384724\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.752823\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 1.501477\n",
      "\n",
      "Test set: Average loss: 1.5246, Accuracy: 4745/10000 (47%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.433134\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 1.403444\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.325262\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 1.377969\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.473406\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 1.486517\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.439110\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 1.384639\n",
      "\n",
      "Test set: Average loss: 1.4951, Accuracy: 4819/10000 (48%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.438260\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 1.470302\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 1.579096\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 1.663655\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.577782\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 1.338940\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 1.590553\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 1.514680\n",
      "\n",
      "Test set: Average loss: 1.4950, Accuracy: 4846/10000 (48%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.519092\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 1.357996\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 1.499218\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 1.332734\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 1.350820\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 1.365156\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 1.336236\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 1.214671\n",
      "\n",
      "Test set: Average loss: 1.4774, Accuracy: 4944/10000 (49%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 1.625307\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 1.618909\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 1.614104\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 1.589830\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 1.493019\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 1.489805\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 1.514354\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 1.513660\n",
      "\n",
      "Test set: Average loss: 1.4752, Accuracy: 4973/10000 (50%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 1.460171\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 1.018501\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 1.484426\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 1.641786\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 1.489138\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 1.311204\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 1.112467\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 1.186042\n",
      "\n",
      "Test set: Average loss: 1.4672, Accuracy: 5018/10000 (50%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 1.506097\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 1.354479\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 1.347692\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 1.439525\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 1.538416\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 1.361192\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 1.468208\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 1.236355\n",
      "\n",
      "Test set: Average loss: 1.4683, Accuracy: 5001/10000 (50%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 1.315681\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 1.313453\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 1.412634\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 1.401957\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 1.400575\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 1.373884\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 1.365166\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 1.365877\n",
      "\n",
      "Test set: Average loss: 1.4680, Accuracy: 5026/10000 (50%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 1.422507\n",
      "Train Epoch: 11 [6400/50000 (13%)]\tLoss: 1.335526\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 1.498840\n",
      "Train Epoch: 11 [19200/50000 (38%)]\tLoss: 1.283800\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 1.380500\n",
      "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 1.367303\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 1.234739\n",
      "Train Epoch: 11 [44800/50000 (90%)]\tLoss: 1.295633\n",
      "\n",
      "Test set: Average loss: 1.4683, Accuracy: 5025/10000 (50%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 1.295144\n",
      "Train Epoch: 12 [6400/50000 (13%)]\tLoss: 1.514587\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 1.268399\n",
      "Train Epoch: 12 [19200/50000 (38%)]\tLoss: 1.407331\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 1.406879\n",
      "Train Epoch: 12 [32000/50000 (64%)]\tLoss: 1.342192\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 1.173773\n",
      "Train Epoch: 12 [44800/50000 (90%)]\tLoss: 1.416951\n",
      "\n",
      "Test set: Average loss: 1.4630, Accuracy: 5041/10000 (50%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 1.440679\n",
      "Train Epoch: 13 [6400/50000 (13%)]\tLoss: 1.216677\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 1.506245\n",
      "Train Epoch: 13 [19200/50000 (38%)]\tLoss: 1.339178\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 1.360041\n",
      "Train Epoch: 13 [32000/50000 (64%)]\tLoss: 1.404442\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 1.509848\n",
      "Train Epoch: 13 [44800/50000 (90%)]\tLoss: 1.409517\n",
      "\n",
      "Test set: Average loss: 1.4648, Accuracy: 5038/10000 (50%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 1.267557\n",
      "Train Epoch: 14 [6400/50000 (13%)]\tLoss: 1.428559\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 1.239522\n",
      "Train Epoch: 14 [19200/50000 (38%)]\tLoss: 1.362025\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 1.473392\n",
      "Train Epoch: 14 [32000/50000 (64%)]\tLoss: 1.479698\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 1.216326\n",
      "Train Epoch: 14 [44800/50000 (90%)]\tLoss: 1.326332\n",
      "\n",
      "Test set: Average loss: 1.4640, Accuracy: 5052/10000 (51%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 1.657375\n",
      "Train Epoch: 15 [6400/50000 (13%)]\tLoss: 1.192092\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 1.545482\n",
      "Train Epoch: 15 [19200/50000 (38%)]\tLoss: 1.349602\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 1.478250\n",
      "Train Epoch: 15 [32000/50000 (64%)]\tLoss: 1.390776\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 1.457054\n",
      "Train Epoch: 15 [44800/50000 (90%)]\tLoss: 1.378813\n",
      "\n",
      "Test set: Average loss: 1.4650, Accuracy: 5043/10000 (50%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 1.195670\n",
      "Train Epoch: 16 [6400/50000 (13%)]\tLoss: 1.371284\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 1.608781\n",
      "Train Epoch: 16 [19200/50000 (38%)]\tLoss: 1.318648\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 1.454277\n",
      "Train Epoch: 16 [32000/50000 (64%)]\tLoss: 1.287476\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 1.533049\n",
      "Train Epoch: 16 [44800/50000 (90%)]\tLoss: 1.466761\n",
      "\n",
      "Test set: Average loss: 1.4642, Accuracy: 5051/10000 (51%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 1.241112\n",
      "Train Epoch: 17 [6400/50000 (13%)]\tLoss: 1.128915\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 1.380952\n",
      "Train Epoch: 17 [19200/50000 (38%)]\tLoss: 1.463102\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 1.348660\n",
      "Train Epoch: 17 [32000/50000 (64%)]\tLoss: 1.236910\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 1.329825\n",
      "Train Epoch: 17 [44800/50000 (90%)]\tLoss: 1.373538\n",
      "\n",
      "Test set: Average loss: 1.4641, Accuracy: 5046/10000 (50%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 1.386052\n",
      "Train Epoch: 18 [6400/50000 (13%)]\tLoss: 1.475723\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 1.445848\n",
      "Train Epoch: 18 [19200/50000 (38%)]\tLoss: 1.432141\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 1.453308\n",
      "Train Epoch: 18 [32000/50000 (64%)]\tLoss: 1.541697\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 1.375281\n",
      "Train Epoch: 18 [44800/50000 (90%)]\tLoss: 1.418158\n",
      "\n",
      "Test set: Average loss: 1.4642, Accuracy: 5048/10000 (50%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 1.454205\n",
      "Train Epoch: 19 [6400/50000 (13%)]\tLoss: 1.238219\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 1.460496\n",
      "Train Epoch: 19 [19200/50000 (38%)]\tLoss: 1.392369\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 1.325262\n",
      "Train Epoch: 19 [32000/50000 (64%)]\tLoss: 1.277274\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 1.231036\n",
      "Train Epoch: 19 [44800/50000 (90%)]\tLoss: 1.511466\n",
      "\n",
      "Test set: Average loss: 1.4643, Accuracy: 5050/10000 (50%)\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 1.500594\n",
      "Train Epoch: 20 [6400/50000 (13%)]\tLoss: 1.240238\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 1.272928\n",
      "Train Epoch: 20 [19200/50000 (38%)]\tLoss: 1.167929\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 1.260259\n",
      "Train Epoch: 20 [32000/50000 (64%)]\tLoss: 1.298687\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 1.359259\n",
      "Train Epoch: 20 [44800/50000 (90%)]\tLoss: 1.299653\n",
      "\n",
      "Test set: Average loss: 1.4642, Accuracy: 5050/10000 (50%)\n",
      "\n",
      "Evaluating HYBRID with CIFAR10\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.273149\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 1.830186\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.924301\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 1.631359\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.737465\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.638884\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.348714\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 1.480903\n",
      "\n",
      "Test set: Average loss: 1.3817, Accuracy: 5088/10000 (51%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.434913\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 1.521054\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.287040\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 1.485738\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.255667\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.212702\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.235022\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 1.208987\n",
      "\n",
      "Test set: Average loss: 1.3169, Accuracy: 5430/10000 (54%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.377120\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 1.157707\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.231753\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 1.185184\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.247935\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.274043\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.307118\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 1.376985\n",
      "\n",
      "Test set: Average loss: 1.2525, Accuracy: 5745/10000 (57%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.007549\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 1.242756\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.232438\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 1.133193\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.295000\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 1.275874\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.350268\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 1.244131\n",
      "\n",
      "Test set: Average loss: 1.2293, Accuracy: 5800/10000 (58%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.987066\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 1.102448\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 1.278013\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 1.259909\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.018422\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 1.143463\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 1.245079\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 1.367429\n",
      "\n",
      "Test set: Average loss: 1.2403, Accuracy: 5853/10000 (59%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.403840\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 1.224694\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.969567\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 0.992080\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 1.172905\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 1.160543\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 1.235822\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 1.460099\n",
      "\n",
      "Test set: Average loss: 1.2063, Accuracy: 5933/10000 (59%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 1.131619\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 1.024119\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 1.068839\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 0.992104\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.957252\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 1.185328\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 1.087664\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 1.094375\n",
      "\n",
      "Test set: Average loss: 1.1972, Accuracy: 5966/10000 (60%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 1.086695\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 1.295523\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.945171\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 1.191615\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 1.162020\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 1.248988\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 1.321430\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 0.901510\n",
      "\n",
      "Test set: Average loss: 1.1793, Accuracy: 6032/10000 (60%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 1.097874\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 1.200328\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 1.050805\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 1.305569\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 1.257673\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 1.082598\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 1.159418\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 1.004732\n",
      "\n",
      "Test set: Average loss: 1.2041, Accuracy: 5966/10000 (60%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 1.080597\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 0.894162\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 1.252041\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 1.359287\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.968490\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 1.158012\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.953606\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 1.244416\n",
      "\n",
      "Test set: Average loss: 1.1877, Accuracy: 6036/10000 (60%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 1.186011\n",
      "Train Epoch: 11 [6400/50000 (13%)]\tLoss: 1.148162\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 1.360988\n",
      "Train Epoch: 11 [19200/50000 (38%)]\tLoss: 1.072098\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.977675\n",
      "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 1.152300\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 0.954558\n",
      "Train Epoch: 11 [44800/50000 (90%)]\tLoss: 1.402349\n",
      "\n",
      "Test set: Average loss: 1.1913, Accuracy: 6016/10000 (60%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 1.148272\n",
      "Train Epoch: 12 [6400/50000 (13%)]\tLoss: 1.154870\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 1.197737\n",
      "Train Epoch: 12 [19200/50000 (38%)]\tLoss: 1.140389\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 1.123776\n",
      "Train Epoch: 12 [32000/50000 (64%)]\tLoss: 1.080999\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 1.079598\n",
      "Train Epoch: 12 [44800/50000 (90%)]\tLoss: 0.948377\n",
      "\n",
      "Test set: Average loss: 1.1856, Accuracy: 6042/10000 (60%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 1.236243\n",
      "Train Epoch: 13 [6400/50000 (13%)]\tLoss: 1.189990\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 1.201256\n",
      "Train Epoch: 13 [19200/50000 (38%)]\tLoss: 1.156580\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 1.382245\n",
      "Train Epoch: 13 [32000/50000 (64%)]\tLoss: 1.278165\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 1.043829\n",
      "Train Epoch: 13 [44800/50000 (90%)]\tLoss: 0.868166\n",
      "\n",
      "Test set: Average loss: 1.1933, Accuracy: 6033/10000 (60%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 1.032709\n",
      "Train Epoch: 14 [6400/50000 (13%)]\tLoss: 1.077608\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 1.065918\n",
      "Train Epoch: 14 [19200/50000 (38%)]\tLoss: 1.020943\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 1.408910\n",
      "Train Epoch: 14 [32000/50000 (64%)]\tLoss: 1.020291\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 0.913136\n",
      "Train Epoch: 14 [44800/50000 (90%)]\tLoss: 1.261562\n",
      "\n",
      "Test set: Average loss: 1.1832, Accuracy: 6059/10000 (61%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.970485\n",
      "Train Epoch: 15 [6400/50000 (13%)]\tLoss: 1.236382\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 1.017676\n",
      "Train Epoch: 15 [19200/50000 (38%)]\tLoss: 0.855366\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 1.132914\n",
      "Train Epoch: 15 [32000/50000 (64%)]\tLoss: 0.972239\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 1.274620\n",
      "Train Epoch: 15 [44800/50000 (90%)]\tLoss: 1.069489\n",
      "\n",
      "Test set: Average loss: 1.1804, Accuracy: 6067/10000 (61%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 1.215660\n",
      "Train Epoch: 16 [6400/50000 (13%)]\tLoss: 0.942827\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 1.151355\n",
      "Train Epoch: 16 [19200/50000 (38%)]\tLoss: 1.143838\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 1.422570\n",
      "Train Epoch: 16 [32000/50000 (64%)]\tLoss: 1.231459\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 1.103093\n",
      "Train Epoch: 16 [44800/50000 (90%)]\tLoss: 1.157419\n",
      "\n",
      "Test set: Average loss: 1.1843, Accuracy: 6054/10000 (61%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 1.058831\n",
      "Train Epoch: 17 [6400/50000 (13%)]\tLoss: 1.228723\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 1.189942\n",
      "Train Epoch: 17 [19200/50000 (38%)]\tLoss: 1.011689\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 1.048635\n",
      "Train Epoch: 17 [32000/50000 (64%)]\tLoss: 0.953874\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 1.047452\n",
      "Train Epoch: 17 [44800/50000 (90%)]\tLoss: 1.042044\n",
      "\n",
      "Test set: Average loss: 1.1869, Accuracy: 6038/10000 (60%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 1.130759\n",
      "Train Epoch: 18 [6400/50000 (13%)]\tLoss: 1.040381\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 1.074869\n",
      "Train Epoch: 18 [19200/50000 (38%)]\tLoss: 1.226040\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 1.042688\n",
      "Train Epoch: 18 [32000/50000 (64%)]\tLoss: 1.018566\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 1.113176\n",
      "Train Epoch: 18 [44800/50000 (90%)]\tLoss: 1.326301\n",
      "\n",
      "Test set: Average loss: 1.1800, Accuracy: 6060/10000 (61%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 0.901746\n",
      "Train Epoch: 19 [6400/50000 (13%)]\tLoss: 1.286335\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 1.065194\n",
      "Train Epoch: 19 [19200/50000 (38%)]\tLoss: 1.095617\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 1.159148\n",
      "Train Epoch: 19 [32000/50000 (64%)]\tLoss: 0.916497\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 0.955060\n",
      "Train Epoch: 19 [44800/50000 (90%)]\tLoss: 1.014738\n",
      "\n",
      "Test set: Average loss: 1.1802, Accuracy: 6064/10000 (61%)\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 1.109561\n",
      "Train Epoch: 20 [6400/50000 (13%)]\tLoss: 1.231072\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 1.182927\n",
      "Train Epoch: 20 [19200/50000 (38%)]\tLoss: 1.197265\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 1.262535\n",
      "Train Epoch: 20 [32000/50000 (64%)]\tLoss: 1.166144\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 1.291746\n",
      "Train Epoch: 20 [44800/50000 (90%)]\tLoss: 1.236513\n",
      "\n",
      "Test set: Average loss: 1.1872, Accuracy: 6049/10000 (60%)\n",
      "\n",
      "Files already downloaded and verified\n",
      "Evaluating MLP with CIFAR100\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 4.600792\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 4.604963\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 4.595656\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 4.596234\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 4.607273\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 4.590805\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 4.598110\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 4.547785\n",
      "\n",
      "Test set: Average loss: 4.5574, Accuracy: 315/10000 (3%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 4.554863\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 4.576985\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 4.543862\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 4.567463\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 4.574280\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 4.547291\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 4.538849\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 4.579924\n",
      "\n",
      "Test set: Average loss: 4.4919, Accuracy: 389/10000 (4%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 4.432346\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 4.515989\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 4.523395\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 4.511587\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 4.460305\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 4.422437\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 4.530697\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 4.394151\n",
      "\n",
      "Test set: Average loss: 4.4404, Accuracy: 457/10000 (5%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 4.360572\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 4.457918\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 4.539633\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 4.326531\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 4.431517\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 4.491491\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 4.435395\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 4.422379\n",
      "\n",
      "Test set: Average loss: 4.4055, Accuracy: 492/10000 (5%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 4.453251\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 4.475971\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 4.371719\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 4.439171\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 4.460140\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 4.458357\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 4.438531\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 4.404424\n",
      "\n",
      "Test set: Average loss: 4.3821, Accuracy: 530/10000 (5%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 4.466941\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 4.310153\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 4.393622\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 4.337802\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 4.437604\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 4.374860\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 4.408996\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 4.442809\n",
      "\n",
      "Test set: Average loss: 4.3660, Accuracy: 544/10000 (5%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 4.450739\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 4.346595\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 4.373252\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 4.494078\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 4.299336\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 4.388148\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 4.368587\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 4.417860\n",
      "\n",
      "Test set: Average loss: 4.3551, Accuracy: 555/10000 (6%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 4.401806\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 4.290056\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 4.382184\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 4.510024\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 4.446039\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 4.455388\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 4.416840\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 4.399515\n",
      "\n",
      "Test set: Average loss: 4.3477, Accuracy: 563/10000 (6%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 4.335129\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 4.437815\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 4.475777\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 4.395980\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 4.386666\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 4.422412\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 4.418962\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 4.398544\n",
      "\n",
      "Test set: Average loss: 4.3424, Accuracy: 571/10000 (6%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 4.416066\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 4.476974\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 4.487656\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 4.482273\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 4.487631\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 4.402429\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 4.390272\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 4.271525\n",
      "\n",
      "Test set: Average loss: 4.3388, Accuracy: 575/10000 (6%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 4.185916\n",
      "Train Epoch: 11 [6400/50000 (13%)]\tLoss: 4.268911\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 4.433518\n",
      "Train Epoch: 11 [19200/50000 (38%)]\tLoss: 4.369539\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 4.308022\n",
      "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 4.357300\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 4.269899\n",
      "Train Epoch: 11 [44800/50000 (90%)]\tLoss: 4.420184\n",
      "\n",
      "Test set: Average loss: 4.3364, Accuracy: 581/10000 (6%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 4.227406\n",
      "Train Epoch: 12 [6400/50000 (13%)]\tLoss: 4.319453\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 4.320546\n",
      "Train Epoch: 12 [19200/50000 (38%)]\tLoss: 4.411674\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 4.311494\n",
      "Train Epoch: 12 [32000/50000 (64%)]\tLoss: 4.339321\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 4.402386\n",
      "Train Epoch: 12 [44800/50000 (90%)]\tLoss: 4.418336\n",
      "\n",
      "Test set: Average loss: 4.3347, Accuracy: 585/10000 (6%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 4.373836\n",
      "Train Epoch: 13 [6400/50000 (13%)]\tLoss: 4.340455\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 4.355125\n",
      "Train Epoch: 13 [19200/50000 (38%)]\tLoss: 4.505192\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 4.608010\n",
      "Train Epoch: 13 [32000/50000 (64%)]\tLoss: 4.441935\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 4.343155\n",
      "Train Epoch: 13 [44800/50000 (90%)]\tLoss: 4.445375\n",
      "\n",
      "Test set: Average loss: 4.3335, Accuracy: 586/10000 (6%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 4.309163\n",
      "Train Epoch: 14 [6400/50000 (13%)]\tLoss: 4.301699\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 4.427883\n",
      "Train Epoch: 14 [19200/50000 (38%)]\tLoss: 4.353619\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 4.480731\n",
      "Train Epoch: 14 [32000/50000 (64%)]\tLoss: 4.386554\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 4.353620\n",
      "Train Epoch: 14 [44800/50000 (90%)]\tLoss: 4.401117\n",
      "\n",
      "Test set: Average loss: 4.3327, Accuracy: 585/10000 (6%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 4.381219\n",
      "Train Epoch: 15 [6400/50000 (13%)]\tLoss: 4.477436\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 4.400348\n",
      "Train Epoch: 15 [19200/50000 (38%)]\tLoss: 4.344593\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 4.359623\n",
      "Train Epoch: 15 [32000/50000 (64%)]\tLoss: 4.378802\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 4.432087\n",
      "Train Epoch: 15 [44800/50000 (90%)]\tLoss: 4.204336\n",
      "\n",
      "Test set: Average loss: 4.3321, Accuracy: 586/10000 (6%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 4.386302\n",
      "Train Epoch: 16 [6400/50000 (13%)]\tLoss: 4.264059\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 4.350126\n",
      "Train Epoch: 16 [19200/50000 (38%)]\tLoss: 4.449081\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 4.409243\n",
      "Train Epoch: 16 [32000/50000 (64%)]\tLoss: 4.400694\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 4.402789\n",
      "Train Epoch: 16 [44800/50000 (90%)]\tLoss: 4.356126\n",
      "\n",
      "Test set: Average loss: 4.3317, Accuracy: 585/10000 (6%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 4.314164\n",
      "Train Epoch: 17 [6400/50000 (13%)]\tLoss: 4.404137\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 4.324784\n",
      "Train Epoch: 17 [19200/50000 (38%)]\tLoss: 4.285249\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 4.411413\n",
      "Train Epoch: 17 [32000/50000 (64%)]\tLoss: 4.303679\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 4.440100\n",
      "Train Epoch: 17 [44800/50000 (90%)]\tLoss: 4.357086\n",
      "\n",
      "Test set: Average loss: 4.3314, Accuracy: 585/10000 (6%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 4.451552\n",
      "Train Epoch: 18 [6400/50000 (13%)]\tLoss: 4.435657\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 4.528181\n",
      "Train Epoch: 18 [19200/50000 (38%)]\tLoss: 4.394629\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 4.456204\n",
      "Train Epoch: 18 [32000/50000 (64%)]\tLoss: 4.309315\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 4.338565\n",
      "Train Epoch: 18 [44800/50000 (90%)]\tLoss: 4.288274\n",
      "\n",
      "Test set: Average loss: 4.3312, Accuracy: 585/10000 (6%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 4.421311\n",
      "Train Epoch: 19 [6400/50000 (13%)]\tLoss: 4.484207\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 4.394015\n",
      "Train Epoch: 19 [19200/50000 (38%)]\tLoss: 4.372658\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 4.350454\n",
      "Train Epoch: 19 [32000/50000 (64%)]\tLoss: 4.442046\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 4.407856\n",
      "Train Epoch: 19 [44800/50000 (90%)]\tLoss: 4.432915\n",
      "\n",
      "Test set: Average loss: 4.3311, Accuracy: 585/10000 (6%)\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 4.417054\n",
      "Train Epoch: 20 [6400/50000 (13%)]\tLoss: 4.366079\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 4.405529\n",
      "Train Epoch: 20 [19200/50000 (38%)]\tLoss: 4.290580\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 4.502688\n",
      "Train Epoch: 20 [32000/50000 (64%)]\tLoss: 4.365792\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 4.444661\n",
      "Train Epoch: 20 [44800/50000 (90%)]\tLoss: 4.482734\n",
      "\n",
      "Test set: Average loss: 4.3310, Accuracy: 585/10000 (6%)\n",
      "\n",
      "Evaluating CNN with CIFAR100\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 4.627106\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 4.605419\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 4.616081\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 4.590450\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 4.556746\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 4.555110\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 4.567249\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 4.526326\n",
      "\n",
      "Test set: Average loss: 4.5308, Accuracy: 417/10000 (4%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 4.546864\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 4.491935\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 4.480960\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 4.485085\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 4.490714\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 4.484535\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 4.480121\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 4.432850\n",
      "\n",
      "Test set: Average loss: 4.4599, Accuracy: 512/10000 (5%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 4.394812\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 4.363019\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 4.385493\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 4.564398\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 4.386220\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 4.504233\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 4.395049\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 4.331345\n",
      "\n",
      "Test set: Average loss: 4.4170, Accuracy: 569/10000 (6%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 4.169376\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 4.295977\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 4.402259\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 4.341477\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 4.368725\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 4.387567\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 4.366667\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 4.270644\n",
      "\n",
      "Test set: Average loss: 4.3935, Accuracy: 612/10000 (6%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 4.384588\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 4.282973\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 4.378748\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 4.297316\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 4.161076\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 4.327144\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 4.193618\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 4.264819\n",
      "\n",
      "Test set: Average loss: 4.3626, Accuracy: 646/10000 (6%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 4.296226\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 4.357442\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 4.360952\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 4.351132\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 4.222548\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 4.263792\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 4.351183\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 4.210803\n",
      "\n",
      "Test set: Average loss: 4.3601, Accuracy: 675/10000 (7%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 4.367360\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 4.473204\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 4.304561\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 4.253119\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 4.408313\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 4.414052\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 4.257717\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 4.305374\n",
      "\n",
      "Test set: Average loss: 4.3511, Accuracy: 683/10000 (7%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 4.382564\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 4.159045\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 4.191455\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 4.233400\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 4.269085\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 4.174860\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 4.233181\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 4.170419\n",
      "\n",
      "Test set: Average loss: 4.3383, Accuracy: 696/10000 (7%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 4.267482\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 4.228945\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 4.326958\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 4.166754\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 4.341526\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 4.135808\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 4.198952\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 4.282617\n",
      "\n",
      "Test set: Average loss: 4.3427, Accuracy: 706/10000 (7%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 4.175324\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 4.345436\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 4.335995\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 4.235175\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 4.266639\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 4.219779\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 4.350834\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 4.197059\n",
      "\n",
      "Test set: Average loss: 4.3458, Accuracy: 696/10000 (7%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 4.269070\n",
      "Train Epoch: 11 [6400/50000 (13%)]\tLoss: 4.207760\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 4.370824\n",
      "Train Epoch: 11 [19200/50000 (38%)]\tLoss: 4.442565\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 4.350630\n",
      "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 4.309782\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 4.379186\n",
      "Train Epoch: 11 [44800/50000 (90%)]\tLoss: 4.376002\n",
      "\n",
      "Test set: Average loss: 4.3341, Accuracy: 710/10000 (7%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 4.178597\n",
      "Train Epoch: 12 [6400/50000 (13%)]\tLoss: 4.293567\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 4.442498\n",
      "Train Epoch: 12 [19200/50000 (38%)]\tLoss: 4.278823\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 4.395772\n",
      "Train Epoch: 12 [32000/50000 (64%)]\tLoss: 4.427556\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 4.219924\n",
      "Train Epoch: 12 [44800/50000 (90%)]\tLoss: 4.185114\n",
      "\n",
      "Test set: Average loss: 4.3297, Accuracy: 719/10000 (7%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 4.111526\n",
      "Train Epoch: 13 [6400/50000 (13%)]\tLoss: 4.355091\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 4.135539\n",
      "Train Epoch: 13 [19200/50000 (38%)]\tLoss: 4.388164\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 4.208441\n",
      "Train Epoch: 13 [32000/50000 (64%)]\tLoss: 4.157000\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 4.263675\n",
      "Train Epoch: 13 [44800/50000 (90%)]\tLoss: 4.310770\n",
      "\n",
      "Test set: Average loss: 4.3265, Accuracy: 707/10000 (7%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 4.233947\n",
      "Train Epoch: 14 [6400/50000 (13%)]\tLoss: 4.328506\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 4.314693\n",
      "Train Epoch: 14 [19200/50000 (38%)]\tLoss: 4.397256\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 4.318551\n",
      "Train Epoch: 14 [32000/50000 (64%)]\tLoss: 4.412925\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 4.263673\n",
      "Train Epoch: 14 [44800/50000 (90%)]\tLoss: 4.352700\n",
      "\n",
      "Test set: Average loss: 4.3276, Accuracy: 711/10000 (7%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 4.355313\n",
      "Train Epoch: 15 [6400/50000 (13%)]\tLoss: 4.263865\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 4.293114\n",
      "Train Epoch: 15 [19200/50000 (38%)]\tLoss: 4.290992\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 4.326203\n",
      "Train Epoch: 15 [32000/50000 (64%)]\tLoss: 4.186110\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 4.242861\n",
      "Train Epoch: 15 [44800/50000 (90%)]\tLoss: 4.202841\n",
      "\n",
      "Test set: Average loss: 4.3314, Accuracy: 705/10000 (7%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 4.187016\n",
      "Train Epoch: 16 [6400/50000 (13%)]\tLoss: 4.217678\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 4.282022\n",
      "Train Epoch: 16 [19200/50000 (38%)]\tLoss: 4.177115\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 4.381956\n",
      "Train Epoch: 16 [32000/50000 (64%)]\tLoss: 4.216019\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 4.295213\n",
      "Train Epoch: 16 [44800/50000 (90%)]\tLoss: 4.195383\n",
      "\n",
      "Test set: Average loss: 4.3394, Accuracy: 701/10000 (7%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 4.322248\n",
      "Train Epoch: 17 [6400/50000 (13%)]\tLoss: 4.237134\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 4.252021\n",
      "Train Epoch: 17 [19200/50000 (38%)]\tLoss: 4.295338\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 4.055122\n",
      "Train Epoch: 17 [32000/50000 (64%)]\tLoss: 4.358003\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 4.286519\n",
      "Train Epoch: 17 [44800/50000 (90%)]\tLoss: 4.282051\n",
      "\n",
      "Test set: Average loss: 4.3326, Accuracy: 711/10000 (7%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 4.344211\n",
      "Train Epoch: 18 [6400/50000 (13%)]\tLoss: 4.206445\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 4.307544\n",
      "Train Epoch: 18 [19200/50000 (38%)]\tLoss: 4.213640\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 4.153800\n",
      "Train Epoch: 18 [32000/50000 (64%)]\tLoss: 4.313430\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 4.309519\n",
      "Train Epoch: 18 [44800/50000 (90%)]\tLoss: 4.121509\n",
      "\n",
      "Test set: Average loss: 4.3221, Accuracy: 725/10000 (7%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 4.424956\n",
      "Train Epoch: 19 [6400/50000 (13%)]\tLoss: 4.407005\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 4.269408\n",
      "Train Epoch: 19 [19200/50000 (38%)]\tLoss: 4.285875\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 4.370709\n",
      "Train Epoch: 19 [32000/50000 (64%)]\tLoss: 4.215105\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 4.184695\n",
      "Train Epoch: 19 [44800/50000 (90%)]\tLoss: 4.262346\n",
      "\n",
      "Test set: Average loss: 4.3259, Accuracy: 708/10000 (7%)\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 4.165884\n",
      "Train Epoch: 20 [6400/50000 (13%)]\tLoss: 4.192694\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 4.376329\n",
      "Train Epoch: 20 [19200/50000 (38%)]\tLoss: 4.220356\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 4.343780\n",
      "Train Epoch: 20 [32000/50000 (64%)]\tLoss: 4.359353\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 4.247875\n",
      "Train Epoch: 20 [44800/50000 (90%)]\tLoss: 4.301574\n",
      "\n",
      "Test set: Average loss: 4.3295, Accuracy: 710/10000 (7%)\n",
      "\n",
      "Evaluating ViT with CIFAR100\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 4.726722\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 4.478857\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 4.315103\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 4.219718\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 4.129976\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 4.056284\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 3.885062\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 3.852157\n",
      "\n",
      "Test set: Average loss: 3.8179, Accuracy: 1324/10000 (13%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 3.784771\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 3.719484\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 3.561911\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 3.675218\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 3.887170\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 3.982308\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 3.838944\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 3.490319\n",
      "\n",
      "Test set: Average loss: 3.6615, Accuracy: 1614/10000 (16%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 3.688660\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 3.656357\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 3.439126\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 3.854835\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 3.541128\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 3.910688\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 3.469184\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 3.471661\n",
      "\n",
      "Test set: Average loss: 3.5710, Accuracy: 1740/10000 (17%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 3.977496\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 3.806246\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 3.478916\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 3.201912\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 3.671265\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 3.432992\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 3.568388\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 3.342459\n",
      "\n",
      "Test set: Average loss: 3.5226, Accuracy: 1809/10000 (18%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 3.571782\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 3.563422\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 3.620296\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 3.428137\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 3.786444\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 3.296573\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 3.538273\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 3.165253\n",
      "\n",
      "Test set: Average loss: 3.4912, Accuracy: 1878/10000 (19%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 3.610909\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 3.422816\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 3.337394\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 3.310552\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 3.366477\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 3.447120\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 2.976692\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 3.321328\n",
      "\n",
      "Test set: Average loss: 3.4757, Accuracy: 1917/10000 (19%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 3.724482\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 3.491125\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 3.466169\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 3.434135\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 3.211109\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 3.392580\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 3.286575\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 3.279632\n",
      "\n",
      "Test set: Average loss: 3.4592, Accuracy: 1938/10000 (19%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 3.174576\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 3.065560\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 3.589138\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 3.248986\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 3.644722\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 3.315005\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 3.558688\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 3.563580\n",
      "\n",
      "Test set: Average loss: 3.4497, Accuracy: 1977/10000 (20%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 3.497790\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 3.616241\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 3.429075\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 3.508059\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 3.534105\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 3.333949\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 3.447570\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 3.628822\n",
      "\n",
      "Test set: Average loss: 3.4440, Accuracy: 1969/10000 (20%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 3.321947\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 3.399207\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 3.343859\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 3.209868\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 3.462179\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 3.291146\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 3.287155\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 3.803636\n",
      "\n",
      "Test set: Average loss: 3.4391, Accuracy: 1976/10000 (20%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 3.044960\n",
      "Train Epoch: 11 [6400/50000 (13%)]\tLoss: 3.143595\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 3.559005\n",
      "Train Epoch: 11 [19200/50000 (38%)]\tLoss: 3.322889\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 3.454847\n",
      "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 3.114761\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 3.490327\n",
      "Train Epoch: 11 [44800/50000 (90%)]\tLoss: 3.445720\n",
      "\n",
      "Test set: Average loss: 3.4381, Accuracy: 1969/10000 (20%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 3.467313\n",
      "Train Epoch: 12 [6400/50000 (13%)]\tLoss: 3.267661\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 3.537431\n",
      "Train Epoch: 12 [19200/50000 (38%)]\tLoss: 3.422439\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 3.235352\n",
      "Train Epoch: 12 [32000/50000 (64%)]\tLoss: 3.397827\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 3.559105\n",
      "Train Epoch: 12 [44800/50000 (90%)]\tLoss: 3.135257\n",
      "\n",
      "Test set: Average loss: 3.4360, Accuracy: 1969/10000 (20%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 3.307596\n",
      "Train Epoch: 13 [6400/50000 (13%)]\tLoss: 3.723600\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 3.228719\n",
      "Train Epoch: 13 [19200/50000 (38%)]\tLoss: 3.292161\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 3.395652\n",
      "Train Epoch: 13 [32000/50000 (64%)]\tLoss: 3.406438\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 3.719429\n",
      "Train Epoch: 13 [44800/50000 (90%)]\tLoss: 3.587249\n",
      "\n",
      "Test set: Average loss: 3.4345, Accuracy: 1976/10000 (20%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 3.315463\n",
      "Train Epoch: 14 [6400/50000 (13%)]\tLoss: 3.342396\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 3.384451\n",
      "Train Epoch: 14 [19200/50000 (38%)]\tLoss: 3.532484\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 3.537632\n",
      "Train Epoch: 14 [32000/50000 (64%)]\tLoss: 3.592407\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 3.594235\n",
      "Train Epoch: 14 [44800/50000 (90%)]\tLoss: 3.277436\n",
      "\n",
      "Test set: Average loss: 3.4332, Accuracy: 1969/10000 (20%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 3.517758\n",
      "Train Epoch: 15 [6400/50000 (13%)]\tLoss: 3.604167\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 3.301502\n",
      "Train Epoch: 15 [19200/50000 (38%)]\tLoss: 3.305109\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 3.467958\n",
      "Train Epoch: 15 [32000/50000 (64%)]\tLoss: 3.252675\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 3.255768\n",
      "Train Epoch: 15 [44800/50000 (90%)]\tLoss: 3.639349\n",
      "\n",
      "Test set: Average loss: 3.4325, Accuracy: 1972/10000 (20%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 3.396118\n",
      "Train Epoch: 16 [6400/50000 (13%)]\tLoss: 3.189444\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 2.953955\n",
      "Train Epoch: 16 [19200/50000 (38%)]\tLoss: 3.253032\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 3.587211\n",
      "Train Epoch: 16 [32000/50000 (64%)]\tLoss: 3.393860\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 3.250492\n",
      "Train Epoch: 16 [44800/50000 (90%)]\tLoss: 3.639932\n",
      "\n",
      "Test set: Average loss: 3.4320, Accuracy: 1970/10000 (20%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 3.396518\n",
      "Train Epoch: 17 [6400/50000 (13%)]\tLoss: 3.181895\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 3.696670\n",
      "Train Epoch: 17 [19200/50000 (38%)]\tLoss: 3.165927\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 3.309482\n",
      "Train Epoch: 17 [32000/50000 (64%)]\tLoss: 3.284318\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 3.463844\n",
      "Train Epoch: 17 [44800/50000 (90%)]\tLoss: 3.482695\n",
      "\n",
      "Test set: Average loss: 3.4317, Accuracy: 1974/10000 (20%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 3.567282\n",
      "Train Epoch: 18 [6400/50000 (13%)]\tLoss: 3.235324\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 3.440307\n",
      "Train Epoch: 18 [19200/50000 (38%)]\tLoss: 2.985434\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 3.253744\n",
      "Train Epoch: 18 [32000/50000 (64%)]\tLoss: 3.278540\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 3.665735\n",
      "Train Epoch: 18 [44800/50000 (90%)]\tLoss: 3.339083\n",
      "\n",
      "Test set: Average loss: 3.4315, Accuracy: 1976/10000 (20%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 3.555182\n",
      "Train Epoch: 19 [6400/50000 (13%)]\tLoss: 3.483780\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 3.446575\n",
      "Train Epoch: 19 [19200/50000 (38%)]\tLoss: 2.957083\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 3.375285\n",
      "Train Epoch: 19 [32000/50000 (64%)]\tLoss: 3.590710\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 3.404565\n",
      "Train Epoch: 19 [44800/50000 (90%)]\tLoss: 3.589726\n",
      "\n",
      "Test set: Average loss: 3.4313, Accuracy: 1977/10000 (20%)\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 3.421155\n",
      "Train Epoch: 20 [6400/50000 (13%)]\tLoss: 3.275742\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 3.561209\n",
      "Train Epoch: 20 [19200/50000 (38%)]\tLoss: 3.444746\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 3.209225\n",
      "Train Epoch: 20 [32000/50000 (64%)]\tLoss: 3.328604\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 3.286705\n",
      "Train Epoch: 20 [44800/50000 (90%)]\tLoss: 3.269195\n",
      "\n",
      "Test set: Average loss: 3.4312, Accuracy: 1978/10000 (20%)\n",
      "\n",
      "Evaluating HYBRID with CIFAR100\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 4.750357\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 4.422562\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 4.298585\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 4.165735\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 4.026773\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 3.856469\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 3.804604\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 3.757829\n",
      "\n",
      "Test set: Average loss: 3.5912, Accuracy: 1634/10000 (16%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 3.517711\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 3.344215\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 3.599138\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 3.530428\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 3.723295\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 3.353966\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 3.480430\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 3.337525\n",
      "\n",
      "Test set: Average loss: 3.3355, Accuracy: 2099/10000 (21%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 3.360123\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 3.369263\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 3.281839\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 2.987315\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 3.219981\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 3.519812\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 3.181510\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 3.335775\n",
      "\n",
      "Test set: Average loss: 3.2207, Accuracy: 2294/10000 (23%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 3.251754\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 3.182686\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 3.218373\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 3.275104\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 3.397426\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 3.396403\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 3.074863\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 2.980363\n",
      "\n",
      "Test set: Average loss: 3.1599, Accuracy: 2398/10000 (24%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 2.932512\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 3.238741\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 2.762881\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 3.640014\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 3.117210\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 2.923406\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 3.421801\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 3.214614\n",
      "\n",
      "Test set: Average loss: 3.1090, Accuracy: 2499/10000 (25%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 2.771829\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 3.255621\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 3.246310\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 3.452295\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 2.930335\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 3.229840\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 3.005720\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 2.848011\n",
      "\n",
      "Test set: Average loss: 3.0772, Accuracy: 2560/10000 (26%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 2.958643\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 3.045573\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 3.151269\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 3.352800\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 3.200510\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 2.801021\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 2.824181\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 3.297729\n",
      "\n",
      "Test set: Average loss: 3.0626, Accuracy: 2581/10000 (26%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 2.894650\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 3.034798\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 3.336608\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 3.111900\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 2.618061\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 2.997786\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 3.155492\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 2.878736\n",
      "\n",
      "Test set: Average loss: 3.0493, Accuracy: 2615/10000 (26%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 3.000390\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 2.915941\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 2.997669\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 3.052696\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 2.855689\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 3.145814\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 3.361173\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 2.817719\n",
      "\n",
      "Test set: Average loss: 3.0346, Accuracy: 2651/10000 (27%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 3.157557\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 3.068887\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 2.966862\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 2.947242\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 2.774646\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 2.895659\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 3.251480\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 2.929840\n",
      "\n",
      "Test set: Average loss: 3.0353, Accuracy: 2661/10000 (27%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 3.255405\n",
      "Train Epoch: 11 [6400/50000 (13%)]\tLoss: 3.153861\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 3.050983\n",
      "Train Epoch: 11 [19200/50000 (38%)]\tLoss: 2.984568\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 2.856927\n",
      "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 3.168624\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 3.180947\n",
      "Train Epoch: 11 [44800/50000 (90%)]\tLoss: 3.050424\n",
      "\n",
      "Test set: Average loss: 3.0284, Accuracy: 2655/10000 (27%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 2.740932\n",
      "Train Epoch: 12 [6400/50000 (13%)]\tLoss: 2.752961\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 2.778833\n",
      "Train Epoch: 12 [19200/50000 (38%)]\tLoss: 2.782200\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 3.015942\n",
      "Train Epoch: 12 [32000/50000 (64%)]\tLoss: 3.009191\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 3.201789\n",
      "Train Epoch: 12 [44800/50000 (90%)]\tLoss: 2.988770\n",
      "\n",
      "Test set: Average loss: 3.0211, Accuracy: 2683/10000 (27%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 3.104030\n",
      "Train Epoch: 13 [6400/50000 (13%)]\tLoss: 2.956208\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 3.091177\n",
      "Train Epoch: 13 [19200/50000 (38%)]\tLoss: 2.869529\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 3.214944\n",
      "Train Epoch: 13 [32000/50000 (64%)]\tLoss: 2.756693\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 3.240708\n",
      "Train Epoch: 13 [44800/50000 (90%)]\tLoss: 3.307620\n",
      "\n",
      "Test set: Average loss: 3.0244, Accuracy: 2665/10000 (27%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 3.095299\n",
      "Train Epoch: 14 [6400/50000 (13%)]\tLoss: 3.033451\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 3.040093\n",
      "Train Epoch: 14 [19200/50000 (38%)]\tLoss: 3.070734\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 3.450746\n",
      "Train Epoch: 14 [32000/50000 (64%)]\tLoss: 2.987610\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 2.829505\n",
      "Train Epoch: 14 [44800/50000 (90%)]\tLoss: 3.305488\n",
      "\n",
      "Test set: Average loss: 3.0188, Accuracy: 2667/10000 (27%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 3.043178\n",
      "Train Epoch: 15 [6400/50000 (13%)]\tLoss: 2.836060\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 2.945419\n",
      "Train Epoch: 15 [19200/50000 (38%)]\tLoss: 3.180238\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 2.804656\n",
      "Train Epoch: 15 [32000/50000 (64%)]\tLoss: 2.842582\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 3.304938\n",
      "Train Epoch: 15 [44800/50000 (90%)]\tLoss: 2.991252\n",
      "\n",
      "Test set: Average loss: 3.0186, Accuracy: 2677/10000 (27%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 3.405330\n",
      "Train Epoch: 16 [6400/50000 (13%)]\tLoss: 3.057001\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 3.307490\n",
      "Train Epoch: 16 [19200/50000 (38%)]\tLoss: 2.867525\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 3.229551\n",
      "Train Epoch: 16 [32000/50000 (64%)]\tLoss: 2.893354\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 2.669205\n",
      "Train Epoch: 16 [44800/50000 (90%)]\tLoss: 2.750247\n",
      "\n",
      "Test set: Average loss: 3.0208, Accuracy: 2673/10000 (27%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 2.978317\n",
      "Train Epoch: 17 [6400/50000 (13%)]\tLoss: 2.949756\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 2.928146\n",
      "Train Epoch: 17 [19200/50000 (38%)]\tLoss: 2.869591\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 3.269032\n",
      "Train Epoch: 17 [32000/50000 (64%)]\tLoss: 2.810484\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 3.398983\n",
      "Train Epoch: 17 [44800/50000 (90%)]\tLoss: 2.805393\n",
      "\n",
      "Test set: Average loss: 3.0231, Accuracy: 2678/10000 (27%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 2.881623\n",
      "Train Epoch: 18 [6400/50000 (13%)]\tLoss: 2.901825\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 3.193103\n",
      "Train Epoch: 18 [19200/50000 (38%)]\tLoss: 3.105311\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 3.148154\n",
      "Train Epoch: 18 [32000/50000 (64%)]\tLoss: 3.131936\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 2.903266\n",
      "Train Epoch: 18 [44800/50000 (90%)]\tLoss: 2.953493\n",
      "\n",
      "Test set: Average loss: 3.0209, Accuracy: 2667/10000 (27%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 3.136140\n",
      "Train Epoch: 19 [6400/50000 (13%)]\tLoss: 3.330735\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 3.143077\n",
      "Train Epoch: 19 [19200/50000 (38%)]\tLoss: 3.049677\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 2.839321\n",
      "Train Epoch: 19 [32000/50000 (64%)]\tLoss: 2.826129\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 2.916812\n",
      "Train Epoch: 19 [44800/50000 (90%)]\tLoss: 2.894919\n",
      "\n",
      "Test set: Average loss: 3.0177, Accuracy: 2681/10000 (27%)\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 3.097866\n",
      "Train Epoch: 20 [6400/50000 (13%)]\tLoss: 3.253951\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 3.521892\n",
      "Train Epoch: 20 [19200/50000 (38%)]\tLoss: 3.014717\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 3.036662\n",
      "Train Epoch: 20 [32000/50000 (64%)]\tLoss: 3.372956\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 2.756398\n",
      "Train Epoch: 20 [44800/50000 (90%)]\tLoss: 3.019880\n",
      "\n",
      "Test set: Average loss: 3.0178, Accuracy: 2672/10000 (27%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#DATASETS    = [\"MNIST\"] \n",
    "#MODEL_TYPES = [\"HYBRID\"]\n",
    "DATASETS    = [\"MNIST\", \"CIFAR10\", \"CIFAR100\"] \n",
    "MODEL_TYPES = [\"MLP\", \"CNN\", \"ViT\", \"HYBRID\"]\n",
    "\n",
    "batch_size      = 64             # Input batch size for training (default: 64)\n",
    "epochs          = 20             # Number of epochs to train (default: 15)\n",
    "lr              = .00001         # Learning rate (default: .00001)\n",
    "gamma           = 0.7            # Learning rate step gamma (default: 0.7)\n",
    "test_batch_size = 1000           # Input batch size for testing (default: 1000)\n",
    "log_dir         = \"./logs/tb\"    # TF log dir (default: \"./logs/tb\")\n",
    "log_interval    = 100            # How many batches to wait before logging training status (default: 10)\n",
    "\n",
    "accuracies, parameters = run(batch_size, test_batch_size, lr, gamma, epochs, log_dir, log_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "times = Timer().get_phases()\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, sharex=True, figsize=(20,10))\n",
    "bar_colors = ['tab:red', 'tab:green', 'tab:blue', 'tab:orange']\n",
    "ax1.bar(list(times.keys()), list(times.values()), color=bar_colors)\n",
    "ax1.set_ylabel('Inference Times (ms)')\n",
    "ax2.bar(list(times.keys()), list(parameters.values()), color=bar_colors)\n",
    "ax2.set_ylabel('Total Parameters')\n",
    "ax3.bar(list(times.keys()), list(accuracies.values()), color=bar_colors)\n",
    "ax3.set_ylabel('Model Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ik",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
