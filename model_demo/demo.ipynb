{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from vit_pytorch import ViT\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "from timer import Timer\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLPNet(nn.Module):\n",
    "    def __init__(self, image_size, num_classes, channels):\n",
    "        super(MLPNet, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(image_size * channels, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, num_classes)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNNet(nn.Module):\n",
    "    def __init__(self, num_classes, channels, image_height, image_width):\n",
    "        super(CNNNet, self).__init__()\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "        self.norm1 = nn.BatchNorm2d(32)\n",
    "        self.norm2 = nn.BatchNorm2d(64)\n",
    "        self.norm3 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(channels, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, 1)\n",
    "\n",
    "        fc_size = self.forward(torch.rand((1, channels, image_height, image_width)), True)\n",
    "\n",
    "        self.fc1 = nn.Linear(fc_size, 64)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x, get_fc_size=False):\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.conv3(x)\n",
    "        x = self.norm3(x)\n",
    "        x = F.relu(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        if get_fc_size:\n",
    "            return x.nelement()\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTNet(nn.Module): \n",
    "    def __init__(self, image_size, patch_size, num_classes, channels):\n",
    "        HIDDEN_SIZE = 768\n",
    "        DEPTH = 6\n",
    "        HEADS = 12\n",
    "        MLP_DIM = 3072\n",
    "        \n",
    "        super(ViTNet, self).__init__()\n",
    "        \n",
    "        self.model = ViT(\n",
    "                        image_size = image_size,\n",
    "                        patch_size = patch_size,\n",
    "                        num_classes = num_classes,\n",
    "                        dim = HIDDEN_SIZE,\n",
    "                        depth = DEPTH,\n",
    "                        heads = HEADS,\n",
    "                        mlp_dim = MLP_DIM,\n",
    "                        channels = channels,\n",
    "                        dropout = 0.1,\n",
    "                        emb_dropout = 0.1\n",
    "                        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridNet(nn.Module):\n",
    "    def __init__(self, image_size, channels, num_classes):\n",
    "        HIDDEN_SIZE = 768\n",
    "        DEPTH = 6\n",
    "        HEADS = 12\n",
    "        MLP_DIM = 3072\n",
    "\n",
    "        super(HybridNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(channels, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "\n",
    "        self.norm1 = nn.BatchNorm2d(32)\n",
    "        self.norm2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "        image_width = int((math.sqrt(image_size) - 4) / 2)\n",
    "\n",
    "        self.vit = ViT(\n",
    "                        image_size = image_width ** 2,\n",
    "                        patch_size = int(image_width / 2),\n",
    "                        num_classes = num_classes,\n",
    "                        dim = HIDDEN_SIZE,\n",
    "                        depth = DEPTH,\n",
    "                        heads = HEADS,\n",
    "                        mlp_dim = MLP_DIM,\n",
    "                        channels = 64,\n",
    "                        dropout = 0.1,\n",
    "                        emb_dropout = 0.1\n",
    "                        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.vit(x)\n",
    "\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, dataset, modeltype, writer, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            with Timer(\"{} {}\".format(modeltype, dataset)):\n",
    "                output = model(data)\n",
    "\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy))\n",
    "    writer.add_scalar('Accuracy/{} {}'.format(modeltype, dataset), accuracy, epoch)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(batch_size, test_batch_size, lr, gamma, epochs, log_dir, log_interval):\n",
    "    # Determine if we should use a GPU\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "\n",
    "    # Reduce precision to speed up training\n",
    "    torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "    if use_cuda:\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    train_kwargs = {'batch_size': batch_size}\n",
    "    test_kwargs  = {'batch_size': test_batch_size}\n",
    "    if use_cuda:\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "    accuracies = {}\n",
    "    parameters = {}\n",
    "    \n",
    "    for dataset in DATASETS:\n",
    "        if dataset == \"MNIST\":\n",
    "            transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307), (0.3081))\n",
    "            ])\n",
    "            train_set = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "            test_set = datasets.MNIST('./data', train=False, transform=transform)\n",
    "            image_height = 28\n",
    "            image_width = 28\n",
    "            patch_size = 14\n",
    "            num_classes = 10\n",
    "            channels = 1\n",
    "        elif dataset == \"CIFAR10\":\n",
    "            transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "            ])\n",
    "            train_set = datasets.CIFAR10('./data', train=True, download=True, transform=transform)\n",
    "            test_set = datasets.CIFAR10('./data', train=False, transform=transform)\n",
    "            image_height = 32\n",
    "            image_width = 32\n",
    "            patch_size = 16\n",
    "            num_classes = 10\n",
    "            channels = 3\n",
    "        elif dataset == \"CIFAR100\":\n",
    "            transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "            ])\n",
    "            train_set = datasets.CIFAR100('./data', train=True, download=True, transform=transform)\n",
    "            test_set = datasets.CIFAR100('./data', train=False, transform=transform)\n",
    "            image_height = 32\n",
    "            image_width = 32\n",
    "            patch_size = 16\n",
    "            num_classes = 100\n",
    "            channels = 3\n",
    "\n",
    "        for model_type in MODEL_TYPES:\n",
    "            print(\"Evaluating {} with {}\".format(model_type, dataset))\n",
    "\n",
    "            train_loader = torch.utils.data.DataLoader(train_set,**train_kwargs)\n",
    "            test_loader  = torch.utils.data.DataLoader(test_set, **test_kwargs)\n",
    "\n",
    "            if model_type == \"MLP\":\n",
    "                model = MLPNet(image_height * image_width, num_classes, channels).to(device)\n",
    "            elif model_type == \"CNN\":\n",
    "                model = CNNNet(num_classes, channels, image_height, image_width).to(device)\n",
    "            elif model_type == \"ViT\":\n",
    "                model = ViTNet(image_height * image_width, patch_size, num_classes, channels).to(device)\n",
    "            elif model_type == \"HYBRID\":\n",
    "                model = HybridNet(image_height * image_width, channels, num_classes).to(device)\n",
    "            \n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "            scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "\n",
    "            max_accuracy = 0\n",
    "            writer = SummaryWriter(log_dir=log_dir)\n",
    "            for epoch in range(1, epochs + 1):\n",
    "                train(model, device, train_loader, optimizer, epoch, log_interval)\n",
    "                accuracy = test(model, device, test_loader, dataset, model_type, writer, epoch)\n",
    "                max_accuracy = max(accuracy, max_accuracy)\n",
    "                scheduler.step()\n",
    "                if (max_accuracy > 98):\n",
    "                    print('Breaking at epoch {}'.format(epoch))\n",
    "                    break\n",
    "\n",
    "            accuracies[\"{} {}\".format(model_type, dataset)] = max_accuracy\n",
    "            parameters[\"{} {}\".format(model_type, dataset)] = count_parameters(model)\n",
    "\n",
    "            torch.save(model.state_dict(), \"{}_{}.pt\".format(model_type, dataset))\n",
    "\n",
    "    return accuracies, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MLP with MNIST\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.319566\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.297877\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.257959\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.233570\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.184375\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.185903\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.004510\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 1.918782\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.806375\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 1.652635\n",
      "\n",
      "Test set: Average loss: 1.4384, Accuracy: 7253/10000 (73%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.543533\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 1.512111\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 1.471872\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 1.435580\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.164201\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.028029\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.136993\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.940199\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.030543\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 1.116726\n",
      "\n",
      "Test set: Average loss: 0.8422, Accuracy: 8048/10000 (80%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.927992\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 1.014883\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.858051\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.897956\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.004576\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.850359\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.940506\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.830340\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.889800\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.954532\n",
      "\n",
      "Test set: Average loss: 0.6860, Accuracy: 8262/10000 (83%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.994875\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.940206\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.832827\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.963333\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.830048\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 1.046114\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.854182\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.843745\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.680578\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.885423\n",
      "\n",
      "Test set: Average loss: 0.6176, Accuracy: 8364/10000 (84%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.876586\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.795101\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.820082\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.872841\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.737796\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.705050\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.959694\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.699661\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.701844\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.719951\n",
      "\n",
      "Test set: Average loss: 0.5802, Accuracy: 8421/10000 (84%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.788878\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.736260\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.892343\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.725990\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.664022\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.712649\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.747591\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.848525\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.732819\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 1.006813\n",
      "\n",
      "Test set: Average loss: 0.5574, Accuracy: 8487/10000 (85%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.686578\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.770591\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.972738\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.704496\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.658322\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.725145\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.592572\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.597098\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.453854\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.907717\n",
      "\n",
      "Test set: Average loss: 0.5429, Accuracy: 8508/10000 (85%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.576340\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.699836\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.556692\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.554303\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.727946\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.679815\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.637027\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.536698\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.584337\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.674652\n",
      "\n",
      "Test set: Average loss: 0.5334, Accuracy: 8532/10000 (85%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.676298\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.650914\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.707769\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.620038\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.633044\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.673058\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.833811\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.866696\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.738540\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.551786\n",
      "\n",
      "Test set: Average loss: 0.5272, Accuracy: 8541/10000 (85%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.712305\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.748808\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.778549\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.842489\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.612826\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.697786\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.653709\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.596516\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.773038\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.625035\n",
      "\n",
      "Test set: Average loss: 0.5229, Accuracy: 8553/10000 (86%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.706460\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.687058\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.830662\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.757667\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.687506\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.619517\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.570263\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.645784\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.896817\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.803914\n",
      "\n",
      "Test set: Average loss: 0.5200, Accuracy: 8563/10000 (86%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.669501\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.708517\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.811689\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.915114\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.741377\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.532903\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.702613\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.571416\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.641511\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.649142\n",
      "\n",
      "Test set: Average loss: 0.5180, Accuracy: 8564/10000 (86%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.802144\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.738475\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.581136\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.660154\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.749099\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.910007\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.781260\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.859710\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.672224\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.674210\n",
      "\n",
      "Test set: Average loss: 0.5166, Accuracy: 8570/10000 (86%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.502312\n",
      "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.801507\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.526609\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.823102\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.841128\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.573076\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.692165\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.680297\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.634888\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.724614\n",
      "\n",
      "Test set: Average loss: 0.5156, Accuracy: 8573/10000 (86%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.599520\n",
      "Train Epoch: 15 [6400/60000 (11%)]\tLoss: 0.564687\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.709199\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 0.796546\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.788793\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.673031\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.565839\n",
      "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 0.833691\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.748671\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 0.667970\n",
      "\n",
      "Test set: Average loss: 0.5149, Accuracy: 8575/10000 (86%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.696837\n",
      "Train Epoch: 16 [6400/60000 (11%)]\tLoss: 0.774944\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.704506\n",
      "Train Epoch: 16 [19200/60000 (32%)]\tLoss: 0.687454\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.791830\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 0.444618\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.634955\n",
      "Train Epoch: 16 [44800/60000 (75%)]\tLoss: 0.561983\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.623978\n",
      "Train Epoch: 16 [57600/60000 (96%)]\tLoss: 0.732826\n",
      "\n",
      "Test set: Average loss: 0.5145, Accuracy: 8575/10000 (86%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.705687\n",
      "Train Epoch: 17 [6400/60000 (11%)]\tLoss: 0.623360\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.591786\n",
      "Train Epoch: 17 [19200/60000 (32%)]\tLoss: 0.692036\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.852636\n",
      "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 0.908899\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.595846\n",
      "Train Epoch: 17 [44800/60000 (75%)]\tLoss: 0.623214\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.886757\n",
      "Train Epoch: 17 [57600/60000 (96%)]\tLoss: 0.588201\n",
      "\n",
      "Test set: Average loss: 0.5141, Accuracy: 8577/10000 (86%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.883550\n",
      "Train Epoch: 18 [6400/60000 (11%)]\tLoss: 0.926334\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.609597\n",
      "Train Epoch: 18 [19200/60000 (32%)]\tLoss: 0.443200\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.622380\n",
      "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 0.726930\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.706023\n",
      "Train Epoch: 18 [44800/60000 (75%)]\tLoss: 0.525914\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.761380\n",
      "Train Epoch: 18 [57600/60000 (96%)]\tLoss: 0.802036\n",
      "\n",
      "Test set: Average loss: 0.5139, Accuracy: 8578/10000 (86%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.606924\n",
      "Train Epoch: 19 [6400/60000 (11%)]\tLoss: 1.058848\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.715957\n",
      "Train Epoch: 19 [19200/60000 (32%)]\tLoss: 0.653354\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.863663\n",
      "Train Epoch: 19 [32000/60000 (53%)]\tLoss: 0.605703\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.649824\n",
      "Train Epoch: 19 [44800/60000 (75%)]\tLoss: 0.745132\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.751563\n",
      "Train Epoch: 19 [57600/60000 (96%)]\tLoss: 0.731696\n",
      "\n",
      "Test set: Average loss: 0.5137, Accuracy: 8579/10000 (86%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.846162\n",
      "Train Epoch: 20 [6400/60000 (11%)]\tLoss: 0.886481\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.653544\n",
      "Train Epoch: 20 [19200/60000 (32%)]\tLoss: 0.714769\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.600267\n",
      "Train Epoch: 20 [32000/60000 (53%)]\tLoss: 0.618281\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.609807\n",
      "Train Epoch: 20 [44800/60000 (75%)]\tLoss: 0.668690\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.528488\n",
      "Train Epoch: 20 [57600/60000 (96%)]\tLoss: 0.684716\n",
      "\n",
      "Test set: Average loss: 0.5136, Accuracy: 8578/10000 (86%)\n",
      "\n",
      "Evaluating CNN with MNIST\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.312966\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.169974\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.960233\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.800565\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.627464\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.517738\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.394476\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 1.267800\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.226262\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 1.064653\n",
      "\n",
      "Test set: Average loss: 1.2351, Accuracy: 8222/10000 (82%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.017830\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.952776\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.922534\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.809636\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.824804\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.724679\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.766496\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.613392\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.647300\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.729824\n",
      "\n",
      "Test set: Average loss: 0.8193, Accuracy: 8953/10000 (90%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.653444\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.784324\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.442630\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.515644\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.563223\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.538732\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.504779\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.554734\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.489904\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.535563\n",
      "\n",
      "Test set: Average loss: 0.6314, Accuracy: 9162/10000 (92%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.399950\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.441906\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.430378\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.422790\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.240343\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.399548\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.502175\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.480973\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.311644\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.358205\n",
      "\n",
      "Test set: Average loss: 0.5416, Accuracy: 9250/10000 (92%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.357769\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.328986\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.307936\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.531751\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.362855\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.277375\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.318412\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.264918\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.247625\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.323486\n",
      "\n",
      "Test set: Average loss: 0.4827, Accuracy: 9297/10000 (93%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.262765\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.519035\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.340075\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.341205\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.326039\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.224042\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.298515\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.276007\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.265287\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.289211\n",
      "\n",
      "Test set: Average loss: 0.4322, Accuracy: 9361/10000 (94%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.268150\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.197412\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.336930\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.175202\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.239541\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.304160\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.270044\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.229180\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.210600\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.282950\n",
      "\n",
      "Test set: Average loss: 0.4176, Accuracy: 9357/10000 (94%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.323155\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.287935\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.319450\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.283899\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.217276\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.228643\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.247846\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.327225\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.376360\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.333488\n",
      "\n",
      "Test set: Average loss: 0.4033, Accuracy: 9374/10000 (94%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.300291\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.256667\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.187364\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.218725\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.299837\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.285360\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.272334\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.261551\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.396824\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.287216\n",
      "\n",
      "Test set: Average loss: 0.3904, Accuracy: 9395/10000 (94%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.194018\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.258789\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.222818\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.183403\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.180557\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.198191\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.366545\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.266669\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.213983\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.260671\n",
      "\n",
      "Test set: Average loss: 0.3851, Accuracy: 9404/10000 (94%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.223974\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.197007\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.243259\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.192940\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.372807\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.155846\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.284274\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.266794\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.252655\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.170741\n",
      "\n",
      "Test set: Average loss: 0.3854, Accuracy: 9394/10000 (94%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.173117\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.299121\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.190019\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.217582\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.323877\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.275099\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.217947\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.176043\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.267722\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.194055\n",
      "\n",
      "Test set: Average loss: 0.3823, Accuracy: 9386/10000 (94%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.197159\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.336043\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.239884\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.331820\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.295654\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.255593\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.280264\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.240609\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.219539\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.221767\n",
      "\n",
      "Test set: Average loss: 0.3788, Accuracy: 9412/10000 (94%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.205592\n",
      "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.174033\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.179497\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.255244\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.305236\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.239330\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.185998\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.256323\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.400192\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.268774\n",
      "\n",
      "Test set: Average loss: 0.3826, Accuracy: 9384/10000 (94%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.250014\n",
      "Train Epoch: 15 [6400/60000 (11%)]\tLoss: 0.266946\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.286219\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 0.222241\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.250395\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.244747\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.280097\n",
      "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 0.224816\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.224140\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 0.205640\n",
      "\n",
      "Test set: Average loss: 0.3688, Accuracy: 9435/10000 (94%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.203622\n",
      "Train Epoch: 16 [6400/60000 (11%)]\tLoss: 0.306790\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.240756\n",
      "Train Epoch: 16 [19200/60000 (32%)]\tLoss: 0.194647\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.215203\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 0.339952\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.194180\n",
      "Train Epoch: 16 [44800/60000 (75%)]\tLoss: 0.363025\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.214458\n",
      "Train Epoch: 16 [57600/60000 (96%)]\tLoss: 0.274291\n",
      "\n",
      "Test set: Average loss: 0.3836, Accuracy: 9372/10000 (94%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.193398\n",
      "Train Epoch: 17 [6400/60000 (11%)]\tLoss: 0.285260\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.219783\n",
      "Train Epoch: 17 [19200/60000 (32%)]\tLoss: 0.221959\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.238547\n",
      "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 0.237031\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.269003\n",
      "Train Epoch: 17 [44800/60000 (75%)]\tLoss: 0.240678\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.232668\n",
      "Train Epoch: 17 [57600/60000 (96%)]\tLoss: 0.328972\n",
      "\n",
      "Test set: Average loss: 0.3828, Accuracy: 9384/10000 (94%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.207875\n",
      "Train Epoch: 18 [6400/60000 (11%)]\tLoss: 0.296758\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.195934\n",
      "Train Epoch: 18 [19200/60000 (32%)]\tLoss: 0.324166\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.317839\n",
      "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 0.416170\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.291334\n",
      "Train Epoch: 18 [44800/60000 (75%)]\tLoss: 0.277078\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.169137\n",
      "Train Epoch: 18 [57600/60000 (96%)]\tLoss: 0.289881\n",
      "\n",
      "Test set: Average loss: 0.3745, Accuracy: 9406/10000 (94%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.232301\n",
      "Train Epoch: 19 [6400/60000 (11%)]\tLoss: 0.155184\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.150831\n",
      "Train Epoch: 19 [19200/60000 (32%)]\tLoss: 0.251594\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.267680\n",
      "Train Epoch: 19 [32000/60000 (53%)]\tLoss: 0.282782\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.272198\n",
      "Train Epoch: 19 [44800/60000 (75%)]\tLoss: 0.127841\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.267038\n",
      "Train Epoch: 19 [57600/60000 (96%)]\tLoss: 0.154268\n",
      "\n",
      "Test set: Average loss: 0.3869, Accuracy: 9344/10000 (93%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.188428\n",
      "Train Epoch: 20 [6400/60000 (11%)]\tLoss: 0.257329\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.237831\n",
      "Train Epoch: 20 [19200/60000 (32%)]\tLoss: 0.198265\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.250581\n",
      "Train Epoch: 20 [32000/60000 (53%)]\tLoss: 0.237619\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.258627\n",
      "Train Epoch: 20 [44800/60000 (75%)]\tLoss: 0.246274\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.294254\n",
      "Train Epoch: 20 [57600/60000 (96%)]\tLoss: 0.161224\n",
      "\n",
      "Test set: Average loss: 0.3712, Accuracy: 9411/10000 (94%)\n",
      "\n",
      "Evaluating ViT with MNIST\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.552578\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.735629\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.520280\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.303846\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.259371\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.232886\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.405057\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.216941\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.101443\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.121286\n",
      "\n",
      "Test set: Average loss: 0.1809, Accuracy: 9461/10000 (95%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.134426\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.309402\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.449438\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.211605\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.230429\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.281620\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.110034\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.162586\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.082385\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.233740\n",
      "\n",
      "Test set: Average loss: 0.1247, Accuracy: 9622/10000 (96%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.242599\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.038788\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.169077\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.214432\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.102818\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.081380\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.051430\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.110020\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.045322\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.109603\n",
      "\n",
      "Test set: Average loss: 0.1063, Accuracy: 9678/10000 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.070233\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.116303\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.054933\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.194287\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.106264\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.125069\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.179600\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.121090\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.122876\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.082867\n",
      "\n",
      "Test set: Average loss: 0.0921, Accuracy: 9726/10000 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.094891\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.181355\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.072066\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.117758\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.193518\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.025791\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.115834\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.066384\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.039327\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.081920\n",
      "\n",
      "Test set: Average loss: 0.0856, Accuracy: 9728/10000 (97%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.104491\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.195515\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.030443\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.033797\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.150093\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.028541\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.116357\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.074532\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.121626\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.083669\n",
      "\n",
      "Test set: Average loss: 0.0850, Accuracy: 9745/10000 (97%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.101321\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.098860\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.192181\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.329011\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.035949\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.094247\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.272629\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.026604\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.202586\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.144649\n",
      "\n",
      "Test set: Average loss: 0.0819, Accuracy: 9753/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.104884\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.068543\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.040062\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.095226\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.051082\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.045001\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.052341\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.088929\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.062246\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.105560\n",
      "\n",
      "Test set: Average loss: 0.0800, Accuracy: 9764/10000 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.118039\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.192184\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.047569\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.041583\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.069554\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.043319\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.127533\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.086429\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.135999\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.073910\n",
      "\n",
      "Test set: Average loss: 0.0805, Accuracy: 9762/10000 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.034164\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.099655\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.137954\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.018377\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.182581\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.231561\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.064028\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.045688\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.243060\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.103818\n",
      "\n",
      "Test set: Average loss: 0.0799, Accuracy: 9768/10000 (98%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.042330\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.124955\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.058445\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.136227\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.045006\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.020560\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.077876\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.023409\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.022789\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.097281\n",
      "\n",
      "Test set: Average loss: 0.0790, Accuracy: 9769/10000 (98%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.039534\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.030939\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.053342\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.059909\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.094425\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.077417\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.117432\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.055764\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.019109\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.100673\n",
      "\n",
      "Test set: Average loss: 0.0786, Accuracy: 9772/10000 (98%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.113184\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.090552\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.023628\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.055954\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.033647\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.157702\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.061118\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.056688\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.014384\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.134225\n",
      "\n",
      "Test set: Average loss: 0.0785, Accuracy: 9769/10000 (98%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.100206\n",
      "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.103171\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.146084\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.058652\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.047291\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.020809\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.076074\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.037331\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.072935\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.024506\n",
      "\n",
      "Test set: Average loss: 0.0786, Accuracy: 9771/10000 (98%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.087339\n",
      "Train Epoch: 15 [6400/60000 (11%)]\tLoss: 0.074306\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.029490\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 0.033508\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.133244\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.087902\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.030525\n",
      "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 0.187242\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.027386\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 0.023825\n",
      "\n",
      "Test set: Average loss: 0.0782, Accuracy: 9770/10000 (98%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.057659\n",
      "Train Epoch: 16 [6400/60000 (11%)]\tLoss: 0.025632\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.135208\n",
      "Train Epoch: 16 [19200/60000 (32%)]\tLoss: 0.038250\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.053066\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 0.074747\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.032980\n",
      "Train Epoch: 16 [44800/60000 (75%)]\tLoss: 0.047808\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.128824\n",
      "Train Epoch: 16 [57600/60000 (96%)]\tLoss: 0.136759\n",
      "\n",
      "Test set: Average loss: 0.0784, Accuracy: 9772/10000 (98%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.039696\n",
      "Train Epoch: 17 [6400/60000 (11%)]\tLoss: 0.014598\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.101848\n",
      "Train Epoch: 17 [19200/60000 (32%)]\tLoss: 0.169181\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.099872\n",
      "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 0.022144\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.025865\n",
      "Train Epoch: 17 [44800/60000 (75%)]\tLoss: 0.036648\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.024276\n",
      "Train Epoch: 17 [57600/60000 (96%)]\tLoss: 0.022924\n",
      "\n",
      "Test set: Average loss: 0.0783, Accuracy: 9772/10000 (98%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.042966\n",
      "Train Epoch: 18 [6400/60000 (11%)]\tLoss: 0.056180\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.018149\n",
      "Train Epoch: 18 [19200/60000 (32%)]\tLoss: 0.089134\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.064305\n",
      "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 0.025896\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.102541\n",
      "Train Epoch: 18 [44800/60000 (75%)]\tLoss: 0.025600\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.119042\n",
      "Train Epoch: 18 [57600/60000 (96%)]\tLoss: 0.034135\n",
      "\n",
      "Test set: Average loss: 0.0783, Accuracy: 9771/10000 (98%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.047209\n",
      "Train Epoch: 19 [6400/60000 (11%)]\tLoss: 0.059432\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.152096\n",
      "Train Epoch: 19 [19200/60000 (32%)]\tLoss: 0.075010\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.192965\n",
      "Train Epoch: 19 [32000/60000 (53%)]\tLoss: 0.058050\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.052007\n",
      "Train Epoch: 19 [44800/60000 (75%)]\tLoss: 0.066229\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.223169\n",
      "Train Epoch: 19 [57600/60000 (96%)]\tLoss: 0.083968\n",
      "\n",
      "Test set: Average loss: 0.0783, Accuracy: 9772/10000 (98%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.089294\n",
      "Train Epoch: 20 [6400/60000 (11%)]\tLoss: 0.046387\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.021300\n",
      "Train Epoch: 20 [19200/60000 (32%)]\tLoss: 0.063355\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.130295\n",
      "Train Epoch: 20 [32000/60000 (53%)]\tLoss: 0.029802\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.034916\n",
      "Train Epoch: 20 [44800/60000 (75%)]\tLoss: 0.087805\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.012699\n",
      "Train Epoch: 20 [57600/60000 (96%)]\tLoss: 0.030944\n",
      "\n",
      "Test set: Average loss: 0.0783, Accuracy: 9770/10000 (98%)\n",
      "\n",
      "Evaluating HYBRID with MNIST\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.481810\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.745224\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.428941\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.269514\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.325039\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.161888\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.199022\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.158494\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.154012\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.252813\n",
      "\n",
      "Test set: Average loss: 0.0995, Accuracy: 9699/10000 (97%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.064959\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.165639\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.159814\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.119682\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.104193\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.072751\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.092547\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.212499\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.068885\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.059297\n",
      "\n",
      "Test set: Average loss: 0.0724, Accuracy: 9770/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.026764\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.054177\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.030268\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.033803\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.098667\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.152232\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.091727\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.182467\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.021052\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.042113\n",
      "\n",
      "Test set: Average loss: 0.0629, Accuracy: 9802/10000 (98%)\n",
      "\n",
      "Breaking at epoch 3\n",
      "Files already downloaded and verified\n",
      "Evaluating MLP with CIFAR10\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.310796\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 2.291093\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 2.247714\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 2.195945\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 2.183110\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 2.204372\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 2.123703\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 2.135393\n",
      "\n",
      "Test set: Average loss: 2.0673, Accuracy: 2682/10000 (27%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 2.095188\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 2.021060\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 2.047074\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 1.967562\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 2.023309\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.970930\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 2.021733\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 2.029233\n",
      "\n",
      "Test set: Average loss: 1.9532, Accuracy: 2977/10000 (30%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 2.012374\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 1.914967\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.990913\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 1.980864\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 2.128712\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.955626\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.942726\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 2.069628\n",
      "\n",
      "Test set: Average loss: 1.9015, Accuracy: 3186/10000 (32%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.919309\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 1.892080\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.930741\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 2.014947\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.981435\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 2.004398\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.854696\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 1.885999\n",
      "\n",
      "Test set: Average loss: 1.8737, Accuracy: 3301/10000 (33%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.872163\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 1.869258\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 1.951582\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 1.834920\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.944389\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 1.931608\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 1.909837\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 1.899108\n",
      "\n",
      "Test set: Average loss: 1.8564, Accuracy: 3371/10000 (34%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.982277\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 1.895025\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 1.815899\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 1.802374\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 1.983427\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 1.930617\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 1.998172\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 1.858432\n",
      "\n",
      "Test set: Average loss: 1.8456, Accuracy: 3420/10000 (34%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 1.825770\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 1.951097\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 1.919306\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 1.881000\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 1.979751\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 1.791057\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 1.915635\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 1.726195\n",
      "\n",
      "Test set: Average loss: 1.8386, Accuracy: 3473/10000 (35%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 1.701728\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 1.781686\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 2.014068\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 1.921960\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 1.995617\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 1.958588\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 1.962291\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 1.893329\n",
      "\n",
      "Test set: Average loss: 1.8340, Accuracy: 3491/10000 (35%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 1.746673\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 1.940934\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 1.799316\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 2.130369\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 1.794807\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 2.013157\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 1.897090\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 2.013367\n",
      "\n",
      "Test set: Average loss: 1.8309, Accuracy: 3497/10000 (35%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 1.892320\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 1.928021\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 2.020372\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 1.761352\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 1.975416\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 1.917838\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 1.746855\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 1.875877\n",
      "\n",
      "Test set: Average loss: 1.8287, Accuracy: 3504/10000 (35%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 2.030685\n",
      "Train Epoch: 11 [6400/50000 (13%)]\tLoss: 1.779879\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 2.002603\n",
      "Train Epoch: 11 [19200/50000 (38%)]\tLoss: 1.854534\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 1.867195\n",
      "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 1.873889\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 1.892010\n",
      "Train Epoch: 11 [44800/50000 (90%)]\tLoss: 1.836885\n",
      "\n",
      "Test set: Average loss: 1.8272, Accuracy: 3514/10000 (35%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 2.023206\n",
      "Train Epoch: 12 [6400/50000 (13%)]\tLoss: 1.861726\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 1.954199\n",
      "Train Epoch: 12 [19200/50000 (38%)]\tLoss: 1.920331\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 2.146842\n",
      "Train Epoch: 12 [32000/50000 (64%)]\tLoss: 1.889515\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 1.967669\n",
      "Train Epoch: 12 [44800/50000 (90%)]\tLoss: 1.856620\n",
      "\n",
      "Test set: Average loss: 1.8261, Accuracy: 3518/10000 (35%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 1.952625\n",
      "Train Epoch: 13 [6400/50000 (13%)]\tLoss: 1.913404\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 1.791209\n",
      "Train Epoch: 13 [19200/50000 (38%)]\tLoss: 1.950903\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 1.823466\n",
      "Train Epoch: 13 [32000/50000 (64%)]\tLoss: 1.780715\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 1.993393\n",
      "Train Epoch: 13 [44800/50000 (90%)]\tLoss: 1.965752\n",
      "\n",
      "Test set: Average loss: 1.8254, Accuracy: 3518/10000 (35%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 1.836105\n",
      "Train Epoch: 14 [6400/50000 (13%)]\tLoss: 1.811516\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 1.773372\n",
      "Train Epoch: 14 [19200/50000 (38%)]\tLoss: 1.947299\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 1.849725\n",
      "Train Epoch: 14 [32000/50000 (64%)]\tLoss: 1.595715\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 1.847763\n",
      "Train Epoch: 14 [44800/50000 (90%)]\tLoss: 1.836075\n",
      "\n",
      "Test set: Average loss: 1.8249, Accuracy: 3515/10000 (35%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 1.790727\n",
      "Train Epoch: 15 [6400/50000 (13%)]\tLoss: 1.849933\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 1.721703\n",
      "Train Epoch: 15 [19200/50000 (38%)]\tLoss: 1.938302\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 1.890042\n",
      "Train Epoch: 15 [32000/50000 (64%)]\tLoss: 1.810946\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 1.857791\n",
      "Train Epoch: 15 [44800/50000 (90%)]\tLoss: 1.809924\n",
      "\n",
      "Test set: Average loss: 1.8245, Accuracy: 3519/10000 (35%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 1.863904\n",
      "Train Epoch: 16 [6400/50000 (13%)]\tLoss: 1.812862\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 1.809492\n",
      "Train Epoch: 16 [19200/50000 (38%)]\tLoss: 1.921264\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 1.989330\n",
      "Train Epoch: 16 [32000/50000 (64%)]\tLoss: 1.823386\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 1.868575\n",
      "Train Epoch: 16 [44800/50000 (90%)]\tLoss: 1.866397\n",
      "\n",
      "Test set: Average loss: 1.8243, Accuracy: 3519/10000 (35%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 1.909270\n",
      "Train Epoch: 17 [6400/50000 (13%)]\tLoss: 1.978714\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 1.809979\n",
      "Train Epoch: 17 [19200/50000 (38%)]\tLoss: 1.950603\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 2.000158\n",
      "Train Epoch: 17 [32000/50000 (64%)]\tLoss: 1.809252\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 1.866617\n",
      "Train Epoch: 17 [44800/50000 (90%)]\tLoss: 1.899023\n",
      "\n",
      "Test set: Average loss: 1.8241, Accuracy: 3522/10000 (35%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 1.907863\n",
      "Train Epoch: 18 [6400/50000 (13%)]\tLoss: 1.939772\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 1.738685\n",
      "Train Epoch: 18 [19200/50000 (38%)]\tLoss: 1.980691\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 1.698418\n",
      "Train Epoch: 18 [32000/50000 (64%)]\tLoss: 2.011386\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 1.764152\n",
      "Train Epoch: 18 [44800/50000 (90%)]\tLoss: 1.917930\n",
      "\n",
      "Test set: Average loss: 1.8240, Accuracy: 3521/10000 (35%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 2.064770\n",
      "Train Epoch: 19 [6400/50000 (13%)]\tLoss: 2.021407\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 1.800084\n",
      "Train Epoch: 19 [19200/50000 (38%)]\tLoss: 1.839622\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 1.903956\n",
      "Train Epoch: 19 [32000/50000 (64%)]\tLoss: 1.855422\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 1.769733\n",
      "Train Epoch: 19 [44800/50000 (90%)]\tLoss: 2.070242\n",
      "\n",
      "Test set: Average loss: 1.8239, Accuracy: 3523/10000 (35%)\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 1.843337\n",
      "Train Epoch: 20 [6400/50000 (13%)]\tLoss: 1.813812\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 1.808969\n",
      "Train Epoch: 20 [19200/50000 (38%)]\tLoss: 1.860579\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 1.769054\n",
      "Train Epoch: 20 [32000/50000 (64%)]\tLoss: 1.814236\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 1.960183\n",
      "Train Epoch: 20 [44800/50000 (90%)]\tLoss: 1.805003\n",
      "\n",
      "Test set: Average loss: 1.8238, Accuracy: 3524/10000 (35%)\n",
      "\n",
      "Evaluating CNN with CIFAR10\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.362422\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 2.266361\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 2.205223\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 2.101096\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 2.017652\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 2.023424\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.999098\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 1.962152\n",
      "\n",
      "Test set: Average loss: 1.9578, Accuracy: 3090/10000 (31%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.915446\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 1.943650\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.841350\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 1.868345\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.929896\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.753746\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.742209\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 1.676497\n",
      "\n",
      "Test set: Average loss: 1.8235, Accuracy: 3418/10000 (34%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.725021\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 1.682448\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.695899\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 1.805203\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.576841\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.562746\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.649573\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 1.522066\n",
      "\n",
      "Test set: Average loss: 1.7400, Accuracy: 3686/10000 (37%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.583752\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 1.569687\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.577545\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 1.578585\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.642360\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 1.501006\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.551474\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 1.582103\n",
      "\n",
      "Test set: Average loss: 1.7017, Accuracy: 3809/10000 (38%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.395969\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 1.558517\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 1.507681\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 1.562707\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.640374\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 1.531037\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 1.560293\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 1.642532\n",
      "\n",
      "Test set: Average loss: 1.6746, Accuracy: 3906/10000 (39%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.697725\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 1.664188\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 1.539535\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 1.716282\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 1.638401\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 1.420964\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 1.716588\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 1.395523\n",
      "\n",
      "Test set: Average loss: 1.6521, Accuracy: 4006/10000 (40%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 1.461226\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 1.512204\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 1.534010\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 1.571559\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 1.525694\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 1.594811\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 1.519712\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 1.563522\n",
      "\n",
      "Test set: Average loss: 1.6610, Accuracy: 3965/10000 (40%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 1.610026\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 1.560063\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 1.648929\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 1.570349\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 1.454746\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 1.276814\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 1.524979\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 1.603009\n",
      "\n",
      "Test set: Average loss: 1.6447, Accuracy: 4013/10000 (40%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 1.589967\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 1.596028\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 1.520670\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 1.495673\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 1.558877\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 1.627081\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 1.349797\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 1.390614\n",
      "\n",
      "Test set: Average loss: 1.6389, Accuracy: 4043/10000 (40%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 1.610716\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 1.571699\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 1.479749\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 1.573915\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 1.435210\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 1.594425\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 1.533879\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 1.678665\n",
      "\n",
      "Test set: Average loss: 1.6367, Accuracy: 4075/10000 (41%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 1.641534\n",
      "Train Epoch: 11 [6400/50000 (13%)]\tLoss: 1.355630\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 1.568707\n",
      "Train Epoch: 11 [19200/50000 (38%)]\tLoss: 1.561688\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 1.525396\n",
      "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 1.562569\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 1.468437\n",
      "Train Epoch: 11 [44800/50000 (90%)]\tLoss: 1.513795\n",
      "\n",
      "Test set: Average loss: 1.6320, Accuracy: 4084/10000 (41%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 1.440809\n",
      "Train Epoch: 12 [6400/50000 (13%)]\tLoss: 1.565484\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 1.538269\n",
      "Train Epoch: 12 [19200/50000 (38%)]\tLoss: 1.656617\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 1.431630\n",
      "Train Epoch: 12 [32000/50000 (64%)]\tLoss: 1.581595\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 1.583626\n",
      "Train Epoch: 12 [44800/50000 (90%)]\tLoss: 1.609281\n",
      "\n",
      "Test set: Average loss: 1.6243, Accuracy: 4123/10000 (41%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 1.442981\n",
      "Train Epoch: 13 [6400/50000 (13%)]\tLoss: 1.566198\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 1.641443\n",
      "Train Epoch: 13 [19200/50000 (38%)]\tLoss: 1.434528\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 1.530254\n",
      "Train Epoch: 13 [32000/50000 (64%)]\tLoss: 1.425782\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 1.598590\n",
      "Train Epoch: 13 [44800/50000 (90%)]\tLoss: 1.653314\n",
      "\n",
      "Test set: Average loss: 1.6327, Accuracy: 4064/10000 (41%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 1.396785\n",
      "Train Epoch: 14 [6400/50000 (13%)]\tLoss: 1.496636\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 1.496154\n",
      "Train Epoch: 14 [19200/50000 (38%)]\tLoss: 1.626168\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 1.589742\n",
      "Train Epoch: 14 [32000/50000 (64%)]\tLoss: 1.513580\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 1.584580\n",
      "Train Epoch: 14 [44800/50000 (90%)]\tLoss: 1.447990\n",
      "\n",
      "Test set: Average loss: 1.6259, Accuracy: 4102/10000 (41%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 1.670092\n",
      "Train Epoch: 15 [6400/50000 (13%)]\tLoss: 1.441716\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 1.457372\n",
      "Train Epoch: 15 [19200/50000 (38%)]\tLoss: 1.301423\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 1.373783\n",
      "Train Epoch: 15 [32000/50000 (64%)]\tLoss: 1.614004\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 1.463981\n",
      "Train Epoch: 15 [44800/50000 (90%)]\tLoss: 1.601801\n",
      "\n",
      "Test set: Average loss: 1.6426, Accuracy: 4018/10000 (40%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 1.556433\n",
      "Train Epoch: 16 [6400/50000 (13%)]\tLoss: 1.386472\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 1.747645\n",
      "Train Epoch: 16 [19200/50000 (38%)]\tLoss: 1.486642\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 1.322996\n",
      "Train Epoch: 16 [32000/50000 (64%)]\tLoss: 1.492757\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 1.502345\n",
      "Train Epoch: 16 [44800/50000 (90%)]\tLoss: 1.505886\n",
      "\n",
      "Test set: Average loss: 1.6228, Accuracy: 4096/10000 (41%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 1.584686\n",
      "Train Epoch: 17 [6400/50000 (13%)]\tLoss: 1.575469\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 1.536225\n",
      "Train Epoch: 17 [19200/50000 (38%)]\tLoss: 1.455462\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 1.531161\n",
      "Train Epoch: 17 [32000/50000 (64%)]\tLoss: 1.587200\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 1.439675\n",
      "Train Epoch: 17 [44800/50000 (90%)]\tLoss: 1.391490\n",
      "\n",
      "Test set: Average loss: 1.6234, Accuracy: 4118/10000 (41%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 1.525798\n",
      "Train Epoch: 18 [6400/50000 (13%)]\tLoss: 1.467747\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 1.725941\n",
      "Train Epoch: 18 [19200/50000 (38%)]\tLoss: 1.606806\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 1.505420\n",
      "Train Epoch: 18 [32000/50000 (64%)]\tLoss: 1.476250\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 1.451098\n",
      "Train Epoch: 18 [44800/50000 (90%)]\tLoss: 1.478608\n",
      "\n",
      "Test set: Average loss: 1.6279, Accuracy: 4085/10000 (41%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 1.550693\n",
      "Train Epoch: 19 [6400/50000 (13%)]\tLoss: 1.406957\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 1.733051\n",
      "Train Epoch: 19 [19200/50000 (38%)]\tLoss: 1.513802\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 1.521828\n",
      "Train Epoch: 19 [32000/50000 (64%)]\tLoss: 1.391835\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 1.627033\n",
      "Train Epoch: 19 [44800/50000 (90%)]\tLoss: 1.582766\n",
      "\n",
      "Test set: Average loss: 1.6303, Accuracy: 4054/10000 (41%)\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 1.430736\n",
      "Train Epoch: 20 [6400/50000 (13%)]\tLoss: 1.525581\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 1.508209\n",
      "Train Epoch: 20 [19200/50000 (38%)]\tLoss: 1.595293\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 1.501527\n",
      "Train Epoch: 20 [32000/50000 (64%)]\tLoss: 1.594167\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 1.543887\n",
      "Train Epoch: 20 [44800/50000 (90%)]\tLoss: 1.672055\n",
      "\n",
      "Test set: Average loss: 1.6370, Accuracy: 4066/10000 (41%)\n",
      "\n",
      "Evaluating ViT with CIFAR10\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.397828\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 1.986408\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.974533\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 1.711777\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.792935\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.545795\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.614382\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 1.565993\n",
      "\n",
      "Test set: Average loss: 1.6917, Accuracy: 4068/10000 (41%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.557751\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 1.833016\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.645208\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 1.326747\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.680957\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.815613\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.389504\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 1.695435\n",
      "\n",
      "Test set: Average loss: 1.5739, Accuracy: 4500/10000 (45%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.615748\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 1.652611\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.505403\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 1.830616\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.398624\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.567759\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.491328\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 1.603969\n",
      "\n",
      "Test set: Average loss: 1.5284, Accuracy: 4702/10000 (47%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.407064\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 1.710080\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.469468\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 1.429990\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.379643\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 1.400689\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.623456\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 1.335555\n",
      "\n",
      "Test set: Average loss: 1.4869, Accuracy: 4855/10000 (49%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.388444\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 1.569951\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 1.418848\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 1.267906\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.343091\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 1.239174\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 1.576474\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 1.492352\n",
      "\n",
      "Test set: Average loss: 1.4870, Accuracy: 4908/10000 (49%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.357197\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 1.290512\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 1.321366\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 1.503994\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 1.429161\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 1.563143\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 1.365429\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 1.484528\n",
      "\n",
      "Test set: Average loss: 1.4821, Accuracy: 4942/10000 (49%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 1.640044\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 1.272967\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 1.272325\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 1.203450\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 1.449773\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 1.709793\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 1.261746\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 1.403072\n",
      "\n",
      "Test set: Average loss: 1.4678, Accuracy: 5005/10000 (50%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 1.622228\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 1.504804\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 1.340379\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 1.451916\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 1.335914\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 1.468521\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 1.125493\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 1.858993\n",
      "\n",
      "Test set: Average loss: 1.4718, Accuracy: 4986/10000 (50%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 1.740206\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 1.355022\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 1.182405\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 1.353757\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 1.464039\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 1.504094\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 1.379556\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 1.443105\n",
      "\n",
      "Test set: Average loss: 1.4648, Accuracy: 5025/10000 (50%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 1.430806\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 1.409170\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 1.562687\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 1.364156\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 1.580679\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 1.479184\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 1.553708\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 1.550375\n",
      "\n",
      "Test set: Average loss: 1.4663, Accuracy: 5009/10000 (50%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 1.342725\n",
      "Train Epoch: 11 [6400/50000 (13%)]\tLoss: 1.320907\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 1.212156\n",
      "Train Epoch: 11 [19200/50000 (38%)]\tLoss: 1.340029\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 1.557490\n",
      "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 1.294680\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 1.262732\n",
      "Train Epoch: 11 [44800/50000 (90%)]\tLoss: 1.257189\n",
      "\n",
      "Test set: Average loss: 1.4670, Accuracy: 5023/10000 (50%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 1.317918\n",
      "Train Epoch: 12 [6400/50000 (13%)]\tLoss: 1.201914\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 1.310485\n",
      "Train Epoch: 12 [19200/50000 (38%)]\tLoss: 1.383578\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 1.111009\n",
      "Train Epoch: 12 [32000/50000 (64%)]\tLoss: 1.375814\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 1.188650\n",
      "Train Epoch: 12 [44800/50000 (90%)]\tLoss: 1.467253\n",
      "\n",
      "Test set: Average loss: 1.4658, Accuracy: 5022/10000 (50%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 1.351367\n",
      "Train Epoch: 13 [6400/50000 (13%)]\tLoss: 1.348402\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 1.337546\n",
      "Train Epoch: 13 [19200/50000 (38%)]\tLoss: 1.368827\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 1.702386\n",
      "Train Epoch: 13 [32000/50000 (64%)]\tLoss: 1.397172\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 1.228999\n",
      "Train Epoch: 13 [44800/50000 (90%)]\tLoss: 1.488575\n",
      "\n",
      "Test set: Average loss: 1.4648, Accuracy: 5037/10000 (50%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 1.514967\n",
      "Train Epoch: 14 [6400/50000 (13%)]\tLoss: 1.464649\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 1.204784\n",
      "Train Epoch: 14 [19200/50000 (38%)]\tLoss: 1.559883\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 1.587314\n",
      "Train Epoch: 14 [32000/50000 (64%)]\tLoss: 1.299937\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 1.267285\n",
      "Train Epoch: 14 [44800/50000 (90%)]\tLoss: 1.378834\n",
      "\n",
      "Test set: Average loss: 1.4645, Accuracy: 5041/10000 (50%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 1.322594\n",
      "Train Epoch: 15 [6400/50000 (13%)]\tLoss: 1.670266\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 1.330654\n",
      "Train Epoch: 15 [19200/50000 (38%)]\tLoss: 1.432535\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 1.207546\n",
      "Train Epoch: 15 [32000/50000 (64%)]\tLoss: 1.280923\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 1.187265\n",
      "Train Epoch: 15 [44800/50000 (90%)]\tLoss: 1.335884\n",
      "\n",
      "Test set: Average loss: 1.4642, Accuracy: 5041/10000 (50%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 1.547614\n",
      "Train Epoch: 16 [6400/50000 (13%)]\tLoss: 1.379829\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 1.399186\n",
      "Train Epoch: 16 [19200/50000 (38%)]\tLoss: 1.157550\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 1.423044\n",
      "Train Epoch: 16 [32000/50000 (64%)]\tLoss: 1.645078\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 1.274533\n",
      "Train Epoch: 16 [44800/50000 (90%)]\tLoss: 1.668189\n",
      "\n",
      "Test set: Average loss: 1.4630, Accuracy: 5036/10000 (50%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 1.441478\n",
      "Train Epoch: 17 [6400/50000 (13%)]\tLoss: 1.312534\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 1.395985\n",
      "Train Epoch: 17 [19200/50000 (38%)]\tLoss: 1.344970\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 1.701858\n",
      "Train Epoch: 17 [32000/50000 (64%)]\tLoss: 1.112692\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 1.460240\n",
      "Train Epoch: 17 [44800/50000 (90%)]\tLoss: 1.366565\n",
      "\n",
      "Test set: Average loss: 1.4631, Accuracy: 5038/10000 (50%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 1.563487\n",
      "Train Epoch: 18 [6400/50000 (13%)]\tLoss: 1.539653\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 1.356532\n",
      "Train Epoch: 18 [19200/50000 (38%)]\tLoss: 1.369445\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 1.321421\n",
      "Train Epoch: 18 [32000/50000 (64%)]\tLoss: 1.340976\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 1.339182\n",
      "Train Epoch: 18 [44800/50000 (90%)]\tLoss: 1.462965\n",
      "\n",
      "Test set: Average loss: 1.4632, Accuracy: 5042/10000 (50%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 1.764401\n",
      "Train Epoch: 19 [6400/50000 (13%)]\tLoss: 1.572530\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 1.558753\n",
      "Train Epoch: 19 [19200/50000 (38%)]\tLoss: 1.352715\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 1.501706\n",
      "Train Epoch: 19 [32000/50000 (64%)]\tLoss: 1.494372\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 1.309759\n",
      "Train Epoch: 19 [44800/50000 (90%)]\tLoss: 1.278965\n",
      "\n",
      "Test set: Average loss: 1.4633, Accuracy: 5043/10000 (50%)\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 1.185213\n",
      "Train Epoch: 20 [6400/50000 (13%)]\tLoss: 1.393552\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 1.400908\n",
      "Train Epoch: 20 [19200/50000 (38%)]\tLoss: 1.418902\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 1.358590\n",
      "Train Epoch: 20 [32000/50000 (64%)]\tLoss: 1.771096\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 1.434138\n",
      "Train Epoch: 20 [44800/50000 (90%)]\tLoss: 1.373582\n",
      "\n",
      "Test set: Average loss: 1.4631, Accuracy: 5045/10000 (50%)\n",
      "\n",
      "Evaluating HYBRID with CIFAR10\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.364723\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 1.919098\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.696154\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 1.728281\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.488546\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.647341\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.413803\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 1.599656\n",
      "\n",
      "Test set: Average loss: 1.3994, Accuracy: 5015/10000 (50%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.350561\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 1.388558\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.445859\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 1.221764\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.192298\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.279538\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.131833\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 1.256430\n",
      "\n",
      "Test set: Average loss: 1.3269, Accuracy: 5326/10000 (53%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.440619\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 1.513698\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.227684\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 1.316413\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.462927\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.530059\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.097657\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 1.498715\n",
      "\n",
      "Test set: Average loss: 1.2478, Accuracy: 5658/10000 (57%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.426561\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 1.397932\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.434443\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 1.378737\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.417423\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 1.306369\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.382757\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 1.448289\n",
      "\n",
      "Test set: Average loss: 1.2444, Accuracy: 5727/10000 (57%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.276304\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 1.394221\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 1.261438\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 1.083692\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.318833\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 1.259313\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 1.081490\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 1.081452\n",
      "\n",
      "Test set: Average loss: 1.2236, Accuracy: 5794/10000 (58%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.384233\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 1.136817\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 1.067552\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 1.368210\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 1.134427\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 1.104240\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 1.176112\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 1.083249\n",
      "\n",
      "Test set: Average loss: 1.2110, Accuracy: 5809/10000 (58%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.994178\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 1.019788\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 1.210375\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 1.171262\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 1.025737\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 0.993553\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 1.337456\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 1.236013\n",
      "\n",
      "Test set: Average loss: 1.2006, Accuracy: 5882/10000 (59%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 1.256725\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 1.158978\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 1.434388\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 1.132938\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 1.098167\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 1.060435\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 1.146997\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 1.493028\n",
      "\n",
      "Test set: Average loss: 1.2043, Accuracy: 5890/10000 (59%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 1.175201\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 1.295739\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 1.371864\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 1.079897\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 1.379128\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 0.851935\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 1.129731\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 1.099143\n",
      "\n",
      "Test set: Average loss: 1.2125, Accuracy: 5869/10000 (59%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 1.184605\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 1.086477\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.923706\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 1.186284\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 1.031816\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 1.069535\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.960629\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 1.002132\n",
      "\n",
      "Test set: Average loss: 1.1997, Accuracy: 5905/10000 (59%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 1.042216\n",
      "Train Epoch: 11 [6400/50000 (13%)]\tLoss: 1.231896\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 1.317088\n",
      "Train Epoch: 11 [19200/50000 (38%)]\tLoss: 1.329613\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 1.232125\n",
      "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 1.111689\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 1.061387\n",
      "Train Epoch: 11 [44800/50000 (90%)]\tLoss: 1.256625\n",
      "\n",
      "Test set: Average loss: 1.1945, Accuracy: 5937/10000 (59%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 1.054109\n",
      "Train Epoch: 12 [6400/50000 (13%)]\tLoss: 1.199919\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 1.059032\n",
      "Train Epoch: 12 [19200/50000 (38%)]\tLoss: 1.503406\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 1.135384\n",
      "Train Epoch: 12 [32000/50000 (64%)]\tLoss: 0.977945\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 1.128326\n",
      "Train Epoch: 12 [44800/50000 (90%)]\tLoss: 1.169739\n",
      "\n",
      "Test set: Average loss: 1.1948, Accuracy: 5932/10000 (59%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 1.314362\n",
      "Train Epoch: 13 [6400/50000 (13%)]\tLoss: 1.277445\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 0.976371\n",
      "Train Epoch: 13 [19200/50000 (38%)]\tLoss: 1.056010\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 1.125058\n",
      "Train Epoch: 13 [32000/50000 (64%)]\tLoss: 1.246516\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 1.247677\n",
      "Train Epoch: 13 [44800/50000 (90%)]\tLoss: 1.127997\n",
      "\n",
      "Test set: Average loss: 1.1915, Accuracy: 5932/10000 (59%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 1.198118\n",
      "Train Epoch: 14 [6400/50000 (13%)]\tLoss: 0.968472\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 1.178187\n",
      "Train Epoch: 14 [19200/50000 (38%)]\tLoss: 0.929801\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 1.058335\n",
      "Train Epoch: 14 [32000/50000 (64%)]\tLoss: 1.003854\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 1.221248\n",
      "Train Epoch: 14 [44800/50000 (90%)]\tLoss: 1.284750\n",
      "\n",
      "Test set: Average loss: 1.1965, Accuracy: 5918/10000 (59%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 1.020356\n",
      "Train Epoch: 15 [6400/50000 (13%)]\tLoss: 1.201033\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 1.301786\n",
      "Train Epoch: 15 [19200/50000 (38%)]\tLoss: 1.198827\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 0.985900\n",
      "Train Epoch: 15 [32000/50000 (64%)]\tLoss: 1.207121\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 1.254406\n",
      "Train Epoch: 15 [44800/50000 (90%)]\tLoss: 1.146615\n",
      "\n",
      "Test set: Average loss: 1.1952, Accuracy: 5939/10000 (59%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 1.018483\n",
      "Train Epoch: 16 [6400/50000 (13%)]\tLoss: 0.934466\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 1.128513\n",
      "Train Epoch: 16 [19200/50000 (38%)]\tLoss: 1.203269\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 1.003898\n",
      "Train Epoch: 16 [32000/50000 (64%)]\tLoss: 1.131199\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 1.217836\n",
      "Train Epoch: 16 [44800/50000 (90%)]\tLoss: 1.221129\n",
      "\n",
      "Test set: Average loss: 1.1967, Accuracy: 5931/10000 (59%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 1.298605\n",
      "Train Epoch: 17 [6400/50000 (13%)]\tLoss: 0.942476\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 1.326421\n",
      "Train Epoch: 17 [19200/50000 (38%)]\tLoss: 1.308927\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 1.230760\n",
      "Train Epoch: 17 [32000/50000 (64%)]\tLoss: 1.183007\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 0.943698\n",
      "Train Epoch: 17 [44800/50000 (90%)]\tLoss: 1.203702\n",
      "\n",
      "Test set: Average loss: 1.1918, Accuracy: 5953/10000 (60%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 1.131536\n",
      "Train Epoch: 18 [6400/50000 (13%)]\tLoss: 1.218142\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 1.192957\n",
      "Train Epoch: 18 [19200/50000 (38%)]\tLoss: 1.019889\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 1.286590\n",
      "Train Epoch: 18 [32000/50000 (64%)]\tLoss: 1.026504\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 1.341218\n",
      "Train Epoch: 18 [44800/50000 (90%)]\tLoss: 1.034672\n",
      "\n",
      "Test set: Average loss: 1.1919, Accuracy: 5931/10000 (59%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 1.122009\n",
      "Train Epoch: 19 [6400/50000 (13%)]\tLoss: 1.274433\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 1.073851\n",
      "Train Epoch: 19 [19200/50000 (38%)]\tLoss: 1.094876\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 1.101120\n",
      "Train Epoch: 19 [32000/50000 (64%)]\tLoss: 1.087530\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 1.092234\n",
      "Train Epoch: 19 [44800/50000 (90%)]\tLoss: 0.921665\n",
      "\n",
      "Test set: Average loss: 1.2011, Accuracy: 5909/10000 (59%)\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 1.080397\n",
      "Train Epoch: 20 [6400/50000 (13%)]\tLoss: 1.068839\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 1.305069\n",
      "Train Epoch: 20 [19200/50000 (38%)]\tLoss: 1.057817\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 1.098377\n",
      "Train Epoch: 20 [32000/50000 (64%)]\tLoss: 1.287431\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 0.997214\n",
      "Train Epoch: 20 [44800/50000 (90%)]\tLoss: 0.985155\n",
      "\n",
      "Test set: Average loss: 1.1948, Accuracy: 5933/10000 (59%)\n",
      "\n",
      "Files already downloaded and verified\n",
      "Evaluating MLP with CIFAR100\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 4.614713\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 4.602782\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 4.600544\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 4.628558\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 4.573939\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 4.579301\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 4.541952\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 4.558270\n",
      "\n",
      "Test set: Average loss: 4.5558, Accuracy: 338/10000 (3%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 4.589157\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 4.579392\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 4.543892\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 4.535477\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 4.544490\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 4.535264\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 4.533235\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 4.503162\n",
      "\n",
      "Test set: Average loss: 4.4983, Accuracy: 388/10000 (4%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 4.524636\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 4.556701\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 4.536767\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 4.502036\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 4.485399\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 4.457630\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 4.425998\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 4.461034\n",
      "\n",
      "Test set: Average loss: 4.4519, Accuracy: 422/10000 (4%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 4.502969\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 4.543428\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 4.569558\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 4.391365\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 4.420606\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 4.450655\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 4.354018\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 4.445077\n",
      "\n",
      "Test set: Average loss: 4.4181, Accuracy: 444/10000 (4%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 4.500011\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 4.434205\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 4.461001\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 4.507739\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 4.435612\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 4.460232\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 4.582293\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 4.429300\n",
      "\n",
      "Test set: Average loss: 4.3950, Accuracy: 464/10000 (5%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 4.351856\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 4.564295\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 4.374172\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 4.293630\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 4.387482\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 4.423621\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 4.392323\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 4.504350\n",
      "\n",
      "Test set: Average loss: 4.3786, Accuracy: 476/10000 (5%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 4.435997\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 4.349743\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 4.349621\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 4.536886\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 4.355968\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 4.390663\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 4.539208\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 4.566045\n",
      "\n",
      "Test set: Average loss: 4.3678, Accuracy: 492/10000 (5%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 4.302499\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 4.360696\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 4.461709\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 4.437347\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 4.481816\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 4.306484\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 4.449283\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 4.405208\n",
      "\n",
      "Test set: Average loss: 4.3604, Accuracy: 497/10000 (5%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 4.425095\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 4.448276\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 4.397851\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 4.472160\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 4.414544\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 4.447886\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 4.445137\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 4.402285\n",
      "\n",
      "Test set: Average loss: 4.3552, Accuracy: 503/10000 (5%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 4.442185\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 4.444681\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 4.359258\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 4.349514\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 4.541821\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 4.479830\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 4.470047\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 4.396309\n",
      "\n",
      "Test set: Average loss: 4.3516, Accuracy: 505/10000 (5%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 4.344678\n",
      "Train Epoch: 11 [6400/50000 (13%)]\tLoss: 4.482292\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 4.347951\n",
      "Train Epoch: 11 [19200/50000 (38%)]\tLoss: 4.487429\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 4.333120\n",
      "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 4.336043\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 4.356082\n",
      "Train Epoch: 11 [44800/50000 (90%)]\tLoss: 4.365725\n",
      "\n",
      "Test set: Average loss: 4.3492, Accuracy: 510/10000 (5%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 4.511281\n",
      "Train Epoch: 12 [6400/50000 (13%)]\tLoss: 4.482487\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 4.402772\n",
      "Train Epoch: 12 [19200/50000 (38%)]\tLoss: 4.317600\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 4.328839\n",
      "Train Epoch: 12 [32000/50000 (64%)]\tLoss: 4.462595\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 4.403558\n",
      "Train Epoch: 12 [44800/50000 (90%)]\tLoss: 4.303164\n",
      "\n",
      "Test set: Average loss: 4.3475, Accuracy: 513/10000 (5%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 4.313545\n",
      "Train Epoch: 13 [6400/50000 (13%)]\tLoss: 4.434189\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 4.355772\n",
      "Train Epoch: 13 [19200/50000 (38%)]\tLoss: 4.350092\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 4.362054\n",
      "Train Epoch: 13 [32000/50000 (64%)]\tLoss: 4.483695\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 4.354729\n",
      "Train Epoch: 13 [44800/50000 (90%)]\tLoss: 4.379898\n",
      "\n",
      "Test set: Average loss: 4.3463, Accuracy: 514/10000 (5%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 4.310794\n",
      "Train Epoch: 14 [6400/50000 (13%)]\tLoss: 4.401113\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 4.442598\n",
      "Train Epoch: 14 [19200/50000 (38%)]\tLoss: 4.504099\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 4.461713\n",
      "Train Epoch: 14 [32000/50000 (64%)]\tLoss: 4.399365\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 4.443157\n",
      "Train Epoch: 14 [44800/50000 (90%)]\tLoss: 4.293328\n",
      "\n",
      "Test set: Average loss: 4.3454, Accuracy: 515/10000 (5%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 4.411876\n",
      "Train Epoch: 15 [6400/50000 (13%)]\tLoss: 4.341465\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 4.476739\n",
      "Train Epoch: 15 [19200/50000 (38%)]\tLoss: 4.361825\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 4.387668\n",
      "Train Epoch: 15 [32000/50000 (64%)]\tLoss: 4.316565\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 4.340999\n",
      "Train Epoch: 15 [44800/50000 (90%)]\tLoss: 4.432936\n",
      "\n",
      "Test set: Average loss: 4.3449, Accuracy: 515/10000 (5%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 4.414603\n",
      "Train Epoch: 16 [6400/50000 (13%)]\tLoss: 4.328840\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 4.385465\n",
      "Train Epoch: 16 [19200/50000 (38%)]\tLoss: 4.441495\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 4.410022\n",
      "Train Epoch: 16 [32000/50000 (64%)]\tLoss: 4.574533\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 4.403491\n",
      "Train Epoch: 16 [44800/50000 (90%)]\tLoss: 4.460489\n",
      "\n",
      "Test set: Average loss: 4.3445, Accuracy: 515/10000 (5%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 4.449047\n",
      "Train Epoch: 17 [6400/50000 (13%)]\tLoss: 4.334721\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 4.270603\n",
      "Train Epoch: 17 [19200/50000 (38%)]\tLoss: 4.358481\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 4.417888\n",
      "Train Epoch: 17 [32000/50000 (64%)]\tLoss: 4.337804\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 4.396279\n",
      "Train Epoch: 17 [44800/50000 (90%)]\tLoss: 4.295044\n",
      "\n",
      "Test set: Average loss: 4.3442, Accuracy: 515/10000 (5%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 4.285554\n",
      "Train Epoch: 18 [6400/50000 (13%)]\tLoss: 4.416315\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 4.519551\n",
      "Train Epoch: 18 [19200/50000 (38%)]\tLoss: 4.443236\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 4.578324\n",
      "Train Epoch: 18 [32000/50000 (64%)]\tLoss: 4.412336\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 4.454831\n",
      "Train Epoch: 18 [44800/50000 (90%)]\tLoss: 4.301819\n",
      "\n",
      "Test set: Average loss: 4.3440, Accuracy: 515/10000 (5%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 4.363645\n",
      "Train Epoch: 19 [6400/50000 (13%)]\tLoss: 4.385768\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 4.307413\n",
      "Train Epoch: 19 [19200/50000 (38%)]\tLoss: 4.466585\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 4.445685\n",
      "Train Epoch: 19 [32000/50000 (64%)]\tLoss: 4.244023\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 4.435179\n",
      "Train Epoch: 19 [44800/50000 (90%)]\tLoss: 4.438685\n",
      "\n",
      "Test set: Average loss: 4.3439, Accuracy: 515/10000 (5%)\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 4.398230\n",
      "Train Epoch: 20 [6400/50000 (13%)]\tLoss: 4.448410\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 4.474886\n",
      "Train Epoch: 20 [19200/50000 (38%)]\tLoss: 4.386305\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 4.481932\n",
      "Train Epoch: 20 [32000/50000 (64%)]\tLoss: 4.425368\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 4.398738\n",
      "Train Epoch: 20 [44800/50000 (90%)]\tLoss: 4.292109\n",
      "\n",
      "Test set: Average loss: 4.3438, Accuracy: 515/10000 (5%)\n",
      "\n",
      "Evaluating CNN with CIFAR100\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 4.613278\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 4.616400\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 4.561430\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 4.582638\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 4.571969\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 4.519640\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 4.557768\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 4.542581\n",
      "\n",
      "Test set: Average loss: 4.5430, Accuracy: 288/10000 (3%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 4.573062\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 4.436923\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 4.422637\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 4.531565\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 4.427310\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 4.545815\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 4.558315\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 4.456164\n",
      "\n",
      "Test set: Average loss: 4.4842, Accuracy: 383/10000 (4%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 4.424561\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 4.448781\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 4.457015\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 4.502625\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 4.348821\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 4.435455\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 4.412797\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 4.477774\n",
      "\n",
      "Test set: Average loss: 4.4456, Accuracy: 451/10000 (5%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 4.447414\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 4.375375\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 4.307597\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 4.329006\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 4.422628\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 4.341879\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 4.291323\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 4.517560\n",
      "\n",
      "Test set: Average loss: 4.4173, Accuracy: 487/10000 (5%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 4.333969\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 4.276012\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 4.389614\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 4.490498\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 4.359551\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 4.330825\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 4.326715\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 4.176563\n",
      "\n",
      "Test set: Average loss: 4.4029, Accuracy: 521/10000 (5%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 4.262910\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 4.262474\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 4.368323\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 4.170705\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 4.427949\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 4.249473\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 4.335671\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 4.397901\n",
      "\n",
      "Test set: Average loss: 4.3882, Accuracy: 550/10000 (6%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 4.300917\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 4.292771\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 4.297410\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 4.344032\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 4.368977\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 4.227201\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 4.474140\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 4.296118\n",
      "\n",
      "Test set: Average loss: 4.3750, Accuracy: 539/10000 (5%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 4.254021\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 4.140999\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 4.233609\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 4.077487\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 4.312728\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 4.297113\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 4.259905\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 4.479104\n",
      "\n",
      "Test set: Average loss: 4.3687, Accuracy: 542/10000 (5%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 4.243588\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 4.244846\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 4.229238\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 4.256377\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 4.258935\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 4.318394\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 4.183054\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 4.271036\n",
      "\n",
      "Test set: Average loss: 4.3609, Accuracy: 562/10000 (6%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 4.184276\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 4.174278\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 4.400598\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 4.316389\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 4.195958\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 4.313656\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 4.279686\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 4.243589\n",
      "\n",
      "Test set: Average loss: 4.3625, Accuracy: 558/10000 (6%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 4.247051\n",
      "Train Epoch: 11 [6400/50000 (13%)]\tLoss: 4.280476\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 4.346499\n",
      "Train Epoch: 11 [19200/50000 (38%)]\tLoss: 4.361745\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 4.331576\n",
      "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 4.375880\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 4.278037\n",
      "Train Epoch: 11 [44800/50000 (90%)]\tLoss: 4.352589\n",
      "\n",
      "Test set: Average loss: 4.3561, Accuracy: 598/10000 (6%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 4.235106\n",
      "Train Epoch: 12 [6400/50000 (13%)]\tLoss: 4.331294\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 4.324220\n",
      "Train Epoch: 12 [19200/50000 (38%)]\tLoss: 4.286507\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 4.258281\n",
      "Train Epoch: 12 [32000/50000 (64%)]\tLoss: 4.315955\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 4.299721\n",
      "Train Epoch: 12 [44800/50000 (90%)]\tLoss: 4.395122\n",
      "\n",
      "Test set: Average loss: 4.3573, Accuracy: 569/10000 (6%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 4.363261\n",
      "Train Epoch: 13 [6400/50000 (13%)]\tLoss: 4.236648\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 4.270701\n",
      "Train Epoch: 13 [19200/50000 (38%)]\tLoss: 4.289338\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 4.305739\n",
      "Train Epoch: 13 [32000/50000 (64%)]\tLoss: 4.181590\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 4.305286\n",
      "Train Epoch: 13 [44800/50000 (90%)]\tLoss: 4.322293\n",
      "\n",
      "Test set: Average loss: 4.3548, Accuracy: 561/10000 (6%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 4.328519\n",
      "Train Epoch: 14 [6400/50000 (13%)]\tLoss: 4.192173\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 4.270198\n",
      "Train Epoch: 14 [19200/50000 (38%)]\tLoss: 4.271115\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 4.223910\n",
      "Train Epoch: 14 [32000/50000 (64%)]\tLoss: 4.146307\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 4.164041\n",
      "Train Epoch: 14 [44800/50000 (90%)]\tLoss: 4.242420\n",
      "\n",
      "Test set: Average loss: 4.3565, Accuracy: 572/10000 (6%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 4.166255\n",
      "Train Epoch: 15 [6400/50000 (13%)]\tLoss: 4.322877\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 4.347651\n",
      "Train Epoch: 15 [19200/50000 (38%)]\tLoss: 4.230734\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 4.329045\n",
      "Train Epoch: 15 [32000/50000 (64%)]\tLoss: 4.230177\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 4.149282\n",
      "Train Epoch: 15 [44800/50000 (90%)]\tLoss: 4.244471\n",
      "\n",
      "Test set: Average loss: 4.3535, Accuracy: 581/10000 (6%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 4.296462\n",
      "Train Epoch: 16 [6400/50000 (13%)]\tLoss: 4.343395\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 4.246829\n",
      "Train Epoch: 16 [19200/50000 (38%)]\tLoss: 4.087495\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 4.227934\n",
      "Train Epoch: 16 [32000/50000 (64%)]\tLoss: 4.267540\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 4.308599\n",
      "Train Epoch: 16 [44800/50000 (90%)]\tLoss: 4.356406\n",
      "\n",
      "Test set: Average loss: 4.3547, Accuracy: 580/10000 (6%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 4.299688\n",
      "Train Epoch: 17 [6400/50000 (13%)]\tLoss: 4.191525\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 4.321654\n",
      "Train Epoch: 17 [19200/50000 (38%)]\tLoss: 4.169446\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 4.301980\n",
      "Train Epoch: 17 [32000/50000 (64%)]\tLoss: 4.302704\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 4.264294\n",
      "Train Epoch: 17 [44800/50000 (90%)]\tLoss: 4.285588\n",
      "\n",
      "Test set: Average loss: 4.3576, Accuracy: 563/10000 (6%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 4.359002\n",
      "Train Epoch: 18 [6400/50000 (13%)]\tLoss: 4.286371\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 4.264675\n",
      "Train Epoch: 18 [19200/50000 (38%)]\tLoss: 4.194493\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 4.233659\n",
      "Train Epoch: 18 [32000/50000 (64%)]\tLoss: 4.249014\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 4.241695\n",
      "Train Epoch: 18 [44800/50000 (90%)]\tLoss: 4.209722\n",
      "\n",
      "Test set: Average loss: 4.3508, Accuracy: 586/10000 (6%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 4.258118\n",
      "Train Epoch: 19 [6400/50000 (13%)]\tLoss: 4.223109\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 4.323326\n",
      "Train Epoch: 19 [19200/50000 (38%)]\tLoss: 4.232488\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 4.444415\n",
      "Train Epoch: 19 [32000/50000 (64%)]\tLoss: 4.253252\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 4.255076\n",
      "Train Epoch: 19 [44800/50000 (90%)]\tLoss: 4.247188\n",
      "\n",
      "Test set: Average loss: 4.3542, Accuracy: 582/10000 (6%)\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 4.260742\n",
      "Train Epoch: 20 [6400/50000 (13%)]\tLoss: 4.295288\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 4.297068\n",
      "Train Epoch: 20 [19200/50000 (38%)]\tLoss: 4.396606\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 4.323750\n",
      "Train Epoch: 20 [32000/50000 (64%)]\tLoss: 4.184443\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 4.228521\n",
      "Train Epoch: 20 [44800/50000 (90%)]\tLoss: 4.307388\n",
      "\n",
      "Test set: Average loss: 4.3565, Accuracy: 592/10000 (6%)\n",
      "\n",
      "Evaluating ViT with CIFAR100\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 4.688390\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 4.479969\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 4.278200\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 4.199336\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 4.026183\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 4.065347\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 3.954060\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 3.788741\n",
      "\n",
      "Test set: Average loss: 3.8183, Accuracy: 1287/10000 (13%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 3.905013\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 3.750636\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 3.710621\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 3.592214\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 3.653360\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 3.783099\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 3.719752\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 3.648626\n",
      "\n",
      "Test set: Average loss: 3.6460, Accuracy: 1577/10000 (16%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 3.866488\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 3.186786\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 3.646805\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 3.775084\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 3.796854\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 3.685917\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 3.545957\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 3.718441\n",
      "\n",
      "Test set: Average loss: 3.5646, Accuracy: 1741/10000 (17%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 3.528061\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 3.725852\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 3.673968\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 3.601518\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 3.808497\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 3.465939\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 3.677722\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 3.392057\n",
      "\n",
      "Test set: Average loss: 3.5135, Accuracy: 1820/10000 (18%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 3.703700\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 3.535919\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 3.588729\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 3.189314\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 3.552324\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 3.523837\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 3.476676\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 3.583275\n",
      "\n",
      "Test set: Average loss: 3.4871, Accuracy: 1863/10000 (19%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 3.493859\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 3.588002\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 3.520900\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 3.520778\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 3.225658\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 3.474803\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 3.421854\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 3.463467\n",
      "\n",
      "Test set: Average loss: 3.4683, Accuracy: 1893/10000 (19%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 3.673420\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 3.317384\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 3.404912\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 3.360366\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 3.392860\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 3.590344\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 3.429457\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 3.612763\n",
      "\n",
      "Test set: Average loss: 3.4526, Accuracy: 1941/10000 (19%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 3.618778\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 3.379515\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 3.415371\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 3.575193\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 3.299716\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 3.379558\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 3.461443\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 3.299591\n",
      "\n",
      "Test set: Average loss: 3.4435, Accuracy: 1962/10000 (20%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 3.766077\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 3.363200\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 3.605940\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 3.396547\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 3.242785\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 3.289401\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 3.282221\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 3.005281\n",
      "\n",
      "Test set: Average loss: 3.4383, Accuracy: 1984/10000 (20%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 3.389928\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 3.432955\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 3.254735\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 3.371514\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 3.324253\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 3.558819\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 3.097100\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 3.413265\n",
      "\n",
      "Test set: Average loss: 3.4312, Accuracy: 1999/10000 (20%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 3.553537\n",
      "Train Epoch: 11 [6400/50000 (13%)]\tLoss: 3.583427\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 3.231951\n",
      "Train Epoch: 11 [19200/50000 (38%)]\tLoss: 3.383388\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 3.354533\n",
      "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 3.135473\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 3.260094\n",
      "Train Epoch: 11 [44800/50000 (90%)]\tLoss: 3.118008\n",
      "\n",
      "Test set: Average loss: 3.4291, Accuracy: 1990/10000 (20%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 3.357160\n",
      "Train Epoch: 12 [6400/50000 (13%)]\tLoss: 3.416756\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 3.426095\n",
      "Train Epoch: 12 [19200/50000 (38%)]\tLoss: 3.342387\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 3.243149\n",
      "Train Epoch: 12 [32000/50000 (64%)]\tLoss: 3.276137\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 3.542772\n",
      "Train Epoch: 12 [44800/50000 (90%)]\tLoss: 3.355114\n",
      "\n",
      "Test set: Average loss: 3.4264, Accuracy: 1994/10000 (20%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 3.457276\n",
      "Train Epoch: 13 [6400/50000 (13%)]\tLoss: 3.111739\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 3.272191\n",
      "Train Epoch: 13 [19200/50000 (38%)]\tLoss: 3.010481\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 3.164597\n",
      "Train Epoch: 13 [32000/50000 (64%)]\tLoss: 3.803537\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 3.318383\n",
      "Train Epoch: 13 [44800/50000 (90%)]\tLoss: 3.438807\n",
      "\n",
      "Test set: Average loss: 3.4247, Accuracy: 2003/10000 (20%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 3.358481\n",
      "Train Epoch: 14 [6400/50000 (13%)]\tLoss: 3.410489\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 3.305309\n",
      "Train Epoch: 14 [19200/50000 (38%)]\tLoss: 3.718991\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 3.169976\n",
      "Train Epoch: 14 [32000/50000 (64%)]\tLoss: 3.191820\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 3.577764\n",
      "Train Epoch: 14 [44800/50000 (90%)]\tLoss: 3.441237\n",
      "\n",
      "Test set: Average loss: 3.4239, Accuracy: 2006/10000 (20%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 3.467012\n",
      "Train Epoch: 15 [6400/50000 (13%)]\tLoss: 3.422014\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 3.290417\n",
      "Train Epoch: 15 [19200/50000 (38%)]\tLoss: 3.379907\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 3.461293\n",
      "Train Epoch: 15 [32000/50000 (64%)]\tLoss: 3.070837\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 3.353575\n",
      "Train Epoch: 15 [44800/50000 (90%)]\tLoss: 3.431300\n",
      "\n",
      "Test set: Average loss: 3.4235, Accuracy: 2004/10000 (20%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 3.095331\n",
      "Train Epoch: 16 [6400/50000 (13%)]\tLoss: 3.365200\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 3.525930\n",
      "Train Epoch: 16 [19200/50000 (38%)]\tLoss: 3.559561\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 3.323792\n",
      "Train Epoch: 16 [32000/50000 (64%)]\tLoss: 3.172872\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 3.317155\n",
      "Train Epoch: 16 [44800/50000 (90%)]\tLoss: 3.195237\n",
      "\n",
      "Test set: Average loss: 3.4231, Accuracy: 2003/10000 (20%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 3.449911\n",
      "Train Epoch: 17 [6400/50000 (13%)]\tLoss: 3.244968\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 3.125582\n",
      "Train Epoch: 17 [19200/50000 (38%)]\tLoss: 3.308199\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 3.445801\n",
      "Train Epoch: 17 [32000/50000 (64%)]\tLoss: 3.317088\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 3.368124\n",
      "Train Epoch: 17 [44800/50000 (90%)]\tLoss: 3.316661\n",
      "\n",
      "Test set: Average loss: 3.4227, Accuracy: 2002/10000 (20%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 3.188390\n",
      "Train Epoch: 18 [6400/50000 (13%)]\tLoss: 3.668990\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 3.630505\n",
      "Train Epoch: 18 [19200/50000 (38%)]\tLoss: 3.452316\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 3.556873\n",
      "Train Epoch: 18 [32000/50000 (64%)]\tLoss: 3.591204\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 3.482058\n",
      "Train Epoch: 18 [44800/50000 (90%)]\tLoss: 3.312896\n",
      "\n",
      "Test set: Average loss: 3.4225, Accuracy: 2006/10000 (20%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 3.432179\n",
      "Train Epoch: 19 [6400/50000 (13%)]\tLoss: 3.300915\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 3.374865\n",
      "Train Epoch: 19 [19200/50000 (38%)]\tLoss: 3.364155\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 3.015332\n",
      "Train Epoch: 19 [32000/50000 (64%)]\tLoss: 3.032552\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 3.265782\n",
      "Train Epoch: 19 [44800/50000 (90%)]\tLoss: 3.457966\n",
      "\n",
      "Test set: Average loss: 3.4223, Accuracy: 2004/10000 (20%)\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 3.151239\n",
      "Train Epoch: 20 [6400/50000 (13%)]\tLoss: 3.243737\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 3.252345\n",
      "Train Epoch: 20 [19200/50000 (38%)]\tLoss: 3.487121\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 3.199561\n",
      "Train Epoch: 20 [32000/50000 (64%)]\tLoss: 3.591331\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 3.412251\n",
      "Train Epoch: 20 [44800/50000 (90%)]\tLoss: 3.311758\n",
      "\n",
      "Test set: Average loss: 3.4222, Accuracy: 2004/10000 (20%)\n",
      "\n",
      "Evaluating HYBRID with CIFAR100\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 4.844022\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 4.432671\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 4.190339\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 4.343634\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 4.008701\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 3.667347\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 3.925378\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 3.656502\n",
      "\n",
      "Test set: Average loss: 3.6169, Accuracy: 1600/10000 (16%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 3.860102\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 3.680548\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 3.565571\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 3.623436\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 3.515832\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 3.634321\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 3.443197\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 3.367762\n",
      "\n",
      "Test set: Average loss: 3.3615, Accuracy: 2008/10000 (20%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 3.344499\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 3.425857\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 3.342270\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 3.462419\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 3.549083\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 3.868760\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 3.689517\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 3.417143\n",
      "\n",
      "Test set: Average loss: 3.2288, Accuracy: 2298/10000 (23%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 3.327623\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 3.018351\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 3.159124\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 3.174395\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 3.430063\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 3.244580\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 3.173529\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 3.082493\n",
      "\n",
      "Test set: Average loss: 3.1601, Accuracy: 2410/10000 (24%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 3.434849\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 3.370963\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 3.170887\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 3.381335\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 3.098106\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 2.881503\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 3.333281\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 3.307473\n",
      "\n",
      "Test set: Average loss: 3.1094, Accuracy: 2498/10000 (25%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 2.946007\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 3.056093\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 3.073860\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 3.450444\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 3.026178\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 3.002207\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 3.287796\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 3.261052\n",
      "\n",
      "Test set: Average loss: 3.0778, Accuracy: 2585/10000 (26%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 3.002643\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 3.143705\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 2.641521\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 2.941233\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 3.110409\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 3.195210\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 3.228130\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 3.314301\n",
      "\n",
      "Test set: Average loss: 3.0626, Accuracy: 2597/10000 (26%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 3.130732\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 3.079706\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 3.291825\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 2.944992\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 2.865815\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 2.899578\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 3.088658\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 3.057136\n",
      "\n",
      "Test set: Average loss: 3.0550, Accuracy: 2624/10000 (26%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 2.980545\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 3.178909\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 2.927433\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 2.829642\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 3.408745\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 2.946831\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 3.079172\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 3.035129\n",
      "\n",
      "Test set: Average loss: 3.0425, Accuracy: 2645/10000 (26%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 3.428044\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 3.103449\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 2.988640\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 2.896354\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 3.311005\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 3.334705\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 2.927170\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 2.919224\n",
      "\n",
      "Test set: Average loss: 3.0392, Accuracy: 2645/10000 (26%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 3.247146\n",
      "Train Epoch: 11 [6400/50000 (13%)]\tLoss: 2.899493\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 3.045796\n",
      "Train Epoch: 11 [19200/50000 (38%)]\tLoss: 3.223922\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 2.830744\n",
      "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 3.352070\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 3.371487\n",
      "Train Epoch: 11 [44800/50000 (90%)]\tLoss: 3.461782\n",
      "\n",
      "Test set: Average loss: 3.0352, Accuracy: 2649/10000 (26%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 3.095830\n",
      "Train Epoch: 12 [6400/50000 (13%)]\tLoss: 3.169708\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 3.191247\n",
      "Train Epoch: 12 [19200/50000 (38%)]\tLoss: 3.114647\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 2.872409\n",
      "Train Epoch: 12 [32000/50000 (64%)]\tLoss: 3.260388\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 2.767431\n",
      "Train Epoch: 12 [44800/50000 (90%)]\tLoss: 3.077045\n",
      "\n",
      "Test set: Average loss: 3.0336, Accuracy: 2648/10000 (26%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 2.974987\n",
      "Train Epoch: 13 [6400/50000 (13%)]\tLoss: 3.457433\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 3.247531\n",
      "Train Epoch: 13 [19200/50000 (38%)]\tLoss: 3.253830\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 2.922477\n",
      "Train Epoch: 13 [32000/50000 (64%)]\tLoss: 3.073304\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 2.856115\n",
      "Train Epoch: 13 [44800/50000 (90%)]\tLoss: 2.968672\n",
      "\n",
      "Test set: Average loss: 3.0319, Accuracy: 2657/10000 (27%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 3.064956\n",
      "Train Epoch: 14 [6400/50000 (13%)]\tLoss: 3.258195\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 2.602680\n",
      "Train Epoch: 14 [19200/50000 (38%)]\tLoss: 3.216750\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 3.125881\n",
      "Train Epoch: 14 [32000/50000 (64%)]\tLoss: 3.334789\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 2.832265\n",
      "Train Epoch: 14 [44800/50000 (90%)]\tLoss: 2.853809\n",
      "\n",
      "Test set: Average loss: 3.0273, Accuracy: 2669/10000 (27%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 3.034595\n",
      "Train Epoch: 15 [6400/50000 (13%)]\tLoss: 2.931206\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 3.352118\n",
      "Train Epoch: 15 [19200/50000 (38%)]\tLoss: 3.293618\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 3.095757\n",
      "Train Epoch: 15 [32000/50000 (64%)]\tLoss: 2.766470\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 3.186904\n",
      "Train Epoch: 15 [44800/50000 (90%)]\tLoss: 3.111620\n",
      "\n",
      "Test set: Average loss: 3.0330, Accuracy: 2654/10000 (27%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 2.889443\n",
      "Train Epoch: 16 [6400/50000 (13%)]\tLoss: 3.153500\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 3.007268\n",
      "Train Epoch: 16 [19200/50000 (38%)]\tLoss: 3.162107\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 3.143982\n",
      "Train Epoch: 16 [32000/50000 (64%)]\tLoss: 3.433101\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 3.167098\n",
      "Train Epoch: 16 [44800/50000 (90%)]\tLoss: 3.031838\n",
      "\n",
      "Test set: Average loss: 3.0238, Accuracy: 2684/10000 (27%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 2.909495\n",
      "Train Epoch: 17 [6400/50000 (13%)]\tLoss: 3.290305\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 2.771691\n",
      "Train Epoch: 17 [19200/50000 (38%)]\tLoss: 3.249650\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 3.062100\n",
      "Train Epoch: 17 [32000/50000 (64%)]\tLoss: 3.080037\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 3.310413\n",
      "Train Epoch: 17 [44800/50000 (90%)]\tLoss: 3.012227\n",
      "\n",
      "Test set: Average loss: 3.0232, Accuracy: 2675/10000 (27%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 3.191782\n",
      "Train Epoch: 18 [6400/50000 (13%)]\tLoss: 3.033431\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 2.918309\n",
      "Train Epoch: 18 [19200/50000 (38%)]\tLoss: 3.005862\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 3.376014\n",
      "Train Epoch: 18 [32000/50000 (64%)]\tLoss: 3.302822\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 3.066286\n",
      "Train Epoch: 18 [44800/50000 (90%)]\tLoss: 2.910493\n",
      "\n",
      "Test set: Average loss: 3.0270, Accuracy: 2666/10000 (27%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 3.001827\n",
      "Train Epoch: 19 [6400/50000 (13%)]\tLoss: 3.022667\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 3.152721\n",
      "Train Epoch: 19 [19200/50000 (38%)]\tLoss: 2.793475\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 3.155489\n",
      "Train Epoch: 19 [32000/50000 (64%)]\tLoss: 2.705167\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 3.271220\n",
      "Train Epoch: 19 [44800/50000 (90%)]\tLoss: 3.010518\n",
      "\n",
      "Test set: Average loss: 3.0241, Accuracy: 2679/10000 (27%)\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 3.040591\n",
      "Train Epoch: 20 [6400/50000 (13%)]\tLoss: 3.207112\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 3.120440\n",
      "Train Epoch: 20 [19200/50000 (38%)]\tLoss: 3.165713\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 3.310748\n",
      "Train Epoch: 20 [32000/50000 (64%)]\tLoss: 3.167753\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 2.969654\n",
      "Train Epoch: 20 [44800/50000 (90%)]\tLoss: 2.924150\n",
      "\n",
      "Test set: Average loss: 3.0252, Accuracy: 2666/10000 (27%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#DATASETS    = [\"MNIST\"] \n",
    "#MODEL_TYPES = [\"HYBRID\"]\n",
    "DATASETS    = [\"MNIST\", \"CIFAR10\", \"CIFAR100\"] \n",
    "MODEL_TYPES = [\"MLP\", \"CNN\", \"ViT\", \"HYBRID\"]\n",
    "\n",
    "batch_size      = 64             # Input batch size for training (default: 64)\n",
    "epochs          = 20             # Number of epochs to train (default: 15)\n",
    "lr              = .00001         # Learning rate (default: .00001)\n",
    "gamma           = 0.7            # Learning rate step gamma (default: 0.7)\n",
    "test_batch_size = 1000           # Input batch size for testing (default: 1000)\n",
    "log_dir         = \"./logs/tb\"    # TF log dir (default: \"./logs/tb\")\n",
    "log_interval    = 100            # How many batches to wait before logging training status (default: 10)\n",
    "\n",
    "accuracies, parameters = run(batch_size, test_batch_size, lr, gamma, epochs, log_dir, log_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "times = Timer().times()\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, sharex=True, figsize=(20,10))\n",
    "bar_colors = ['tab:red', 'tab:green', 'tab:blue', 'tab:orange']\n",
    "ax1.bar(list(times.keys()), list(times.values()), color=bar_colors)\n",
    "ax1.set_ylabel('Inference Times (ms)')\n",
    "ax2.bar(list(times.keys()), list(parameters.values()), color=bar_colors)\n",
    "ax2.set_ylabel('Total Parameters')\n",
    "ax3.bar(list(times.keys()), list(accuracies.values()), color=bar_colors)\n",
    "ax3.set_ylabel('Model Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ik",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
