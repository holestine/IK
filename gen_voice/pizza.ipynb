{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pizza Bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize ChatGPT with your personal key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from key import openai_key, wit_key\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a prompt for an automated LLM service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = [ {'role':'system', 'content':\"\"\"\n",
    "You are an OrderBot, an automated service to collect orders for a pizza restaurant. \\\n",
    "You first greet the customer, then collect the order and then ask if it's a pickup or delivery. \\\n",
    "You wait to collect the entire order, then summarize it and check for a final time if the customer wants to add anything else. \\\n",
    "If it's a delivery, you ask for an address. \\\n",
    "Finally you collect the payment.\\\n",
    "Make sure to clarify all options, extras and sizes to uniquely identify the item from the menu.\\\n",
    "You respond in a short, very conversational friendly style. \\\n",
    "Don't allow orders for things not on the menu. \\\n",
    "The menu includes \\\n",
    "pepperoni pizza  12.95, 10.00, 7.00 \\\n",
    "cheese pizza   10.95, 9.25, 6.50 \\\n",
    "eggplant pizza   11.95, 9.75, 6.75 \\\n",
    "fries 4.50, 3.50 \\\n",
    "greek salad 7.25 \\\n",
    "Toppings: \\\n",
    "extra cheese 2.00, \\\n",
    "mushrooms 1.50 \\\n",
    "sausage 3.00 \\\n",
    "canadian bacon 3.50 \\\n",
    "AI sauce 1.50 \\\n",
    "peppers 1.00 \\\n",
    "Drinks: \\\n",
    "coke 3.00, 2.00, 1.00 \\\n",
    "sprite 3.00, 2.00, 1.00 \\\n",
    "bottled water 5.00 \\\n",
    "\"\"\"} ]  # accumulate messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method sends the current dialog to ChatGPT and returns the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_completion_from_messages(messages, model=\"gpt-4o-mini\", temperature=0):\n",
    "    response = client.chat.completions.create(model=model, messages=messages, temperature=temperature)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method appends the new user prompt to the context, gets a response and appends that to the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_messages(prompt):\n",
    "    context.append({'role':'user', 'content':f\"{prompt}\"})\n",
    "    response = get_completion_from_messages(context) \n",
    "    context.append({'role':'assistant', 'content':f\"{response}\"})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_response = None\n",
    "while human_response != 'done':\n",
    "    gpt_response   = collect_messages(human_response)\n",
    "    print(gpt_response)\n",
    "    human_response = input(f\"\\n{gpt_response}\\n\\n\")\n",
    "    print(human_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text 2 Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speech2.wav\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "i = 2\n",
    "speech_file_path = Path(f\"speech{i}.wav\")\n",
    "print(speech_file_path)\n",
    "\n",
    "response = client.audio.speech.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"alloy\",\n",
    "    input=\"Today is a wonderful day to build something people love!\"\n",
    ")\n",
    "\n",
    "# The following method is depricated and gives a warning but still seems to work fine.\n",
    "#response.stream_to_file(speech_file_path)\n",
    "# This does the same thing without the warning\n",
    "response.write_to_file(speech_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech 2 Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from os import path\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from timer import Timer\n",
    "\n",
    "def wav2text(speech_file_path, service):\n",
    "    AUDIO_FILE = path.join('.', speech_file_path)\n",
    "\n",
    "    # Sometimes audio files don't have the necessary headers, this will add them\n",
    "    x,_ = librosa.load(AUDIO_FILE, sr=16000)\n",
    "    sf.write(AUDIO_FILE, x, 16000)\n",
    "\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(AUDIO_FILE) as source:\n",
    "        audio = r.record(source)  # read the entire audio file\n",
    "\n",
    "    with Timer(service):\n",
    "        if service == 'Sphinx':\n",
    "            text = r.recognize_sphinx(audio)\n",
    "        elif service =='GoogleSpeech':\n",
    "            text = r.recognize_google(audio)\n",
    "        elif service =='GoogleCloudSpeech':\n",
    "            # You will need a Google Cloud account, enable the Cloud Speech-to-Text API\n",
    "            # and create a credentials file to use this service. Get started by following\n",
    "            # these instructions https://cloud.google.com/iam/docs/keys-create-delete#python\n",
    "            text = r.recognize_google_cloud(audio, 'google_cloud_credentials.json')\n",
    "        elif service =='Wit':\n",
    "            # You will need to create an account at https://wit.ai/ and generate \n",
    "            # a 'Client Access Token' for the key argument\n",
    "            text = r.recognize_wit(audio, key=wit_key)\n",
    "\n",
    "            #with open('test.wav', 'rb') as f:\n",
    "            #text = client.speech(audio, {'Content-Type': 'audio/wav'})\n",
    "\n",
    "    # recognize speech using Sphinx\n",
    "    try:\n",
    "        print(f\"{service} thinks you said {text}\")\n",
    "    except sr.UnknownValueError:\n",
    "        print(f\"{service} could not understand audio\")\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"{service} error; {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_file_path = 'speech2.wav'\n",
    "for _ in range(10):\n",
    "    wav2text(speech_file_path, 'Sphinx')\n",
    "    wav2text(speech_file_path, 'GoogleSpeech')\n",
    "    wav2text(speech_file_path, 'GoogleCloudSpeech')\n",
    "    wav2text(speech_file_path, 'Wit')\n",
    "\n",
    "Timer().report()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have the conversation in gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_messages(message, history):\n",
    "    context.append({'role':'user', 'content':f\"{message}\"})\n",
    "    response = get_completion_from_messages(context) \n",
    "    context.append({'role':'assistant', 'content':f\"{response}\"})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\holes\\.conda\\envs\\ik\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%blocks\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.ChatInterface(collect_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ik",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
